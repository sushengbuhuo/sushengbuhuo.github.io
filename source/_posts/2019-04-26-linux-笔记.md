---
title: linux 笔记
date: 2019-04-26 16:54:15
tags:
- linux
---
### 磁盘空间不足
```javascript
df命令查看当前计算器磁盘空闲情况
 df -a
 从根目录下开始使用du命令查找出空间占用最大的文件
  du -sh /*命令一路追查
 [root@test-os testuser]# df -h   ###物理磁盘空间 查看所有block使用情况
 Filesystem      Size  Used Avail Use% Mounted on
 /dev/sda3       8.8G  8.8G     0 100% /
 tmpfs           931M     0  931M   0% /dev/shm
 /dev/sda1       190M   40M  141M  22% /boot
 [root@test-os testuser]# du -sh /usr/* |grep G  ###查找大文件
 7.3G    /usr/local
 [root@test-os testuser]# du -sh /usr/local/* |grep G
 7.3G    /usr/local/bin
 [root@test-os testuser]# du -sh /usr/local/bin/* |grep G
 7.3G    /usr/local/bin/1g
 
 [root@test-os testuser]# rm -f /usr/local/bin/1g  ###删除大文件
有些文件删除时还被其它进程占用，此时文件并未真正删除，只是标记为 deleted，只有进程结束后才会将文件真正从磁盘中清除。
 [root@test-os ~]# lsof |grep deleted 
 rsyslogd   1250      root    1w      REG                8,3 4888889358     140789 /var/log/messages (deleted)
 
 [root@test-os ~]# #lsof 显示出系统中被打开的文件 
 [root@test-os ~]# #第一列 软件/服务的名称
 [root@test-os ~]# #第八列 文件的大小 
 [root@test-os ~]# #第10列 文件的名字
 [root@test-os ~]# #第11列 标记（硬链接数为0 进程调用数不为零 就会有 delete)
 
 ####重启对应的服务 释放磁盘空间 
 [root@test-os ~]# /etc/init.d/rsyslog restart 
 --------------------- 
 [root@test-os ~]# df -h
 Filesystem      Size  Used Avail Use% Mounted on
 /dev/sda3       8.8G  1.5G  6.9G  18% /
 tmpfs           931M     0  931M   0% /dev/shm
 /dev/sda1       190M   40M  141M  22% /boot
 /tmp/1m        1003K   19K  933K   2% /app/logs
 --------------------- 
 # df -ih 节点磁盘空间
 Filesystem Inodes IUsed IFree IUse% Mounted on
 /dev/vda1 1.9M 299K 1.6M 17% /
 udev  123K 299 123K 1% /dev
 tmpfs  126K 249 125K 1% /run
 tmpfs  126K 4 126K 1% /run/lock
 tmpfs  126K 2 126K 1% /run/shm
 可以看到，inode 区域只被占用了一小部分，还有大量的空间未使用，所以也不是 inode 区域被占满的问题。
 查看哪个目录占用过大：
 
 cd /;du  -sh ./* |sort -nr|more
 发现 /var/spool/postfix/maildrop 这个目录占用了12G 多的空间
 删除这个目录下的内容(通过管道的方式删除,避免参数过长导致无法执行)：
 
 ls | xargs rm -f
 lsof test.log
 这命令只能在文件被写入的时候才能显示内容，最后虽然得到了个进程号，但是因为写完进程就关闭了，所以还是查不到
 
    for i in /home/*; do echo $i; find $i |wc -l; done
 
    通过该命令可以查看每个用户home下inode的占用情况。如果某个目录下的inode很大，那就是问题所在了。
 
```
### git push 报错 fatal: HttpRequestException encountered.
```javascript
Github 禁用了TLS v1.0 and v1.1，必须更新Windows的git凭证管理器

https://github.com/Microsoft/Git-Credential-Manager-for-Windows/releases/tag/v1.18.2

下载并安装后即可解决
 
```
### pip install 失败
```javascript

 pip install myqr
Collecting myqr
  Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProxyError('Cannot connect to proxy.', NewConnectionError('<pip._vendor.urllib3.connection.VerifiedHTTPSConnection object at 0x03B22330>: Failed to establish a new connection: [WinError 10061] 由于目
标计算机积极拒绝，无法连接。'))': /simple/myqr/
打开Internet选项，选择连接–局域网设置  全部取消勾选，问题解决
https://blog.csdn.net/u010784236/article/details/51820284
```
### awk
```javascript
$ echo 'this is a test' | awk '{print $0}'
$ awk -F ':' '{ print $1 }' demo.txt
$(NF-1) 代表倒数第二个字段。
 
$ awk -F ':' '{print $1, $(NF-1)}' demo.txt
 NR 表示当前处理的是第几行。
 
$ awk -F ':' '{print NR ") " $1}' demo.txt
awk -F ':' '{ print toupper($1) }' demo.txt
awk -F ':' '/usr/ {print $1}' demo.txt #awk ‘条件 动作’ 文件名  print 命令前面是一个正则表达式，只输出包含 usr 的行
awk -F ':' 'NR % 2 == 1 {print $1}' demo.txt 输出奇数行
awk -F ':' '{if ($1 > "m") print $1}' demo.txt
$ awk -F ':' '{if ($1 > "m") print $1; else print "---"}' demo.txt
```
### 批量删除 .DS_Store 文件
`find /home/path -name ".DS_Store" -type f -delete`

### 查看硬盘及内存空间
```javascript
 
# 查看内存及swap大小
free -m
# 查看当前文件夹下所有文件大小（包括子文件夹）
du -sh
# 查看指定文件夹下所有文件大小
du -h /tmp
# 查看tmp目录(包含子目录)的大小
du -ah /tmp

# 查看指定文件夹大小
du -hs ftp
# 查看磁盘剩余空间
df -hl
# 查看每个根路径的分区大小
df -h
# 返回该目录的大小
du -sh [目录名]
# 返回该文件夹总M数
du -sm [文件夹]
```
### 统计文件或目录的个数
```javascript
# 统计文件夹下文件的个数
ls -l | grep '^-' | wc -l
# 统计文件夹下目录的个数
ls -l | grep '^d' | wc -l
# 统计文件夹下文件的个数(包括子文件夹里的)
ls -lR | grep '^-' | wc -l
# 统计文件夹下目录的个数(包括子文件夹里的)
ls -lR | grep '^d' | wc -l
# 统计/var/www目录下的所有py文件
ls -l /var/www | grep py | wc -l
# 统计/var/www目录下(包括子文件夹里的)的所有py文件
ls -lR /var/www | grep py | wc -l
```
### 查看CPU和内存占用
```javascript
# CPU占用最多的前10个进程： 
ps auxw|head -1;ps auxw|sort -rn -k3|head -10 
# 内存消耗最多的前10个进程 
ps auxw|head -1;ps auxw|sort -rn -k4|head -10 
# 虚拟内存使用最多的前10个进程 
ps auxw|head -1;ps auxw|sort -rn -k5|head -10
 按内存占用对进程排序
ps auxw --sort=rss
# 按CPU占用对进程排序
ps auxw --sort=%cpu

查看所有运行的进程
ps -A
```
### curl
```javascript
强制指定本地端口
curl --local-port 51 http://web.example.com

# 查看连接的详细信息
# --trace-time 跟踪/详细输出时，添加时间戳
curl -Sv --trace-time http://web.example.com

```
### 连接你服务器 top10 用户端的 IP 地址
```javascript
netstat -nat | awk '{print $5}' | awk -F ':' '{print $1}' | sort | uniq -c | sort -rn | head -n 10


```
### 最常用的10个命令
```javascript
cat .bash_history | sort | uniq -c | sort -rn | head -n 10 (or cat .zhistory | sort | uniq -c | sort -rn | head -n 10


```
### alias
```javascript
alias nis="npm install --save "
alias svim='sudo vim'
alias mkcd='foo(){ mkdir -p "$1"; cd "$1" }; foo '
alias install='sudo apt get install'
alias update='sudo apt-get update; sudo apt-get upgrade'
alias ..="cd .."
alias ...="cd ..; cd .."
alias www='python -m SimpleHTTPServer 8000'
alias sock5='ssh -D 8080 -q -C -N -f user@your.server'
```
### wget
```javascript
wget http://www.openss7.org/repos/tarballs/strx25-0.9.2.1.ta
$ wget -b http://www.openss7.org/repos/tarballs/strx25-0.9.2.1.tar.bz2
Continuing in background, pid 1984.
Output will be written to `wget-log'.
wget -i download-file-list.txt


```
### 防火墙
```javascript
sudo firewall-cmd --zone=public --add-port=60001/udp --permanent
sudo firewall-cmd --reload
#之后检查新的防火墙规则
firewall-cmd --list-all

//临时关闭防火墙,重启后会重新自动打开
systemctl restart firewalld
//检查防火墙状态
firewall-cmd --state
firewall-cmd --list-all
//Disable firewall
systemctl disable firewalld
systemctl stop firewalld
systemctl status firewalld
//Enable firewall
systemctl enable firewalld
systemctl start firewalld
systemctl status firewalld
```
### 显示 Path 环境变量
```javascript
 $ echo $PATH | tr : \\n
/data2/node-v6.11.0-linux-x64//bin
/usr/bin
/bin
/usr/sbin
/sbin
/usr/local/bin
/usr/local/sbin
/data0/opt/python27/bin

```
### 判断字符串包含
```javascript
if [[ $tar =~ tar.gz ]];then echo "包含";fi
```
### 快速修改后缀名字
```javascript
ll
CentOS-base.repo.repo.bak
epel.repo.repo.bak

ls *.bak|awk -F. '{print $1}'|xargs -t -i mv {}.repo.repo.bak {}.repo
```
### 数值排序
```javascript
sort -t ":" -k 3 -n /etc/passwd
```
### 清理httpd服务日志超过3天的内容
```javascript
0 5 * * * /usr/bin/find /var/log/httpd/ -type f -mtime +3 -exec rm -rf {} \;
```
### awk获取json
```javascript
{"name": "michael", "sex": "male", "pkg_url": "www.github.com", "number": "888"}

pkg_url=$(echo $env | awk -F "pkg_url\": \"" '{print $2}' | awk -F "\"," '{print $1}')
echo $pkg_url
www.github.com
```
### cpu
```javascript
查看 CPU 的型号

 cat /proc/cpuinfo | grep 'model name' | sort | uniq
查看 CPU 颗数

实际 Server 中插槽上的 CPU 个数，物理 cpu 数量，可以数不重复的 physical id 个数。

cat /proc/cpuinfo | grep 'physical id' | sort | uniq | wc -l
查看 CPU 核数

一颗 CPU 上面能处理数据的芯片组的数量。

cat /proc/cpuinfo |grep "cores"|uniq|awk '{print $4}'
top 命令查询出来的就是逻辑 CPU 的数量。

cat /proc/cpuinfo |grep "processor"|wc -l
https://learnku.com/articles/32681
```
### 查看系统负载
```javascript
$ uptime\
16:33:56 up 69 days,  5:10,  1 user,  load average: 0.14, 0.24, 0.29
以上信息的解析如下：

16:33:56 : 当前时间
up 69 days, 5:10 : 系统运行了 69 天 5 小时 10 分
1 user : 当前有 1 个用户登录了系统 load average: 0.14, 0.24, 0.29 : 系统在过去 1 分钟内，5 分钟内，15 分钟内的平均负载
load average: 0.14, 0.24, 0.29 : 系统在过去 1 分钟内，5 分钟内，15 分钟内的平均负载
平均负载解析

查看逻辑 CPU 核心数：

$ grep 'model name' /proc/cpuinfo | wc -l\
1\
运行结果表示，有 1 个逻辑 CPU 核心。以 1 个 CPU 核心为例，假设 CPU 每分钟最多处理 100 个进程 –

load=0，没有进程需要 CPU
load=0.5，CPU 处理了 50 个进程
load=1, CPU 处理了 100 个进程，这时 CPU 已被占满，但系统还是能顺畅运作的
load=1.5, CPU 处理了 100 个进程，还有 50 个进程正在排除等着 CPU 处理，这时，CPU 已经超负荷工作了
为了系统顺畅运行，load 值最好不要超过 1.0，这样就没有进程需要等待了，所有进程都能第一时间得到处理。\
很显然，1.0 是一个关键值，超过这个值，系统就不在最佳状态了。 一般 0.7 是一个比较理想的值。\
另外，load 值的健康状态还跟系统 CPU 核心数相关，如果 CPU 核心数为 2，那么 load 值健康值应该为 2，以此类推。 \
评价系统的负载一般采用 15 分钟内的那个平均负载值。

二、w 命令

$ w\
 17:47:40 up 69 days,  6:24,  1 user,  load average: 0.46, 0.26, 0.25\
USER     TTY      FROM              LOGIN@   IDLE   JCPU   PCPU WHAT\
lvinkim  pts/0    14.18.144.2      15:55    0.00s  0.02s  0.00s w
第 1 行：与 uptime 一相同。 \
第 2 行以下，当前登录用户的列表。

三、top 命令

$ top\
top - 17:51:23 up 69 days,  6:28,  1 user,  load average: 0.31, 0.30, 0.26\
Tasks:  99 total,   1 running,  98 sleeping,   0 stopped,   0 zombie\
Cpu(s):  2.3%us,  0.2%sy,  0.0%ni, 97.4%id,  0.0%wa,  0.0%hi,  0.0%si,  0.0%st\
Mem:   1922244k total,  1737480k used,   184764k free,   208576k buffers\
Swap:        0k total,        0k used,        0k free,   466732k cached\
\
  PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  COMMAND                                                                \
    1 root      20   0 19232 1004  708 S  0.0  0.1   0:01.17 init                                                                    \
    2 root      20   0     0    0    0 S  0.0  0.0   0:00.01 kthreadd                                                                \
...
第 1 行：与 uptime 一相同。

第 2 行：进程数信息。

Tasks: 99 total : 总共有 99 个进程
1 running : 1 个进程正在占用 CPU
98 sleeping : 98 个睡眠进程
0 stopped : 0 个停止的进程
0 zombie : 0 个僵尸进程
第 3 行 : CPU 使用率

us (user): 非 nice 用户进程占用 CPU 的比率
sy (system): 内核、内核进程占用 CPU 的比率
ni (nice): 用户进程空间内改变过优先级的进程占用 CPU 比率
id (idle): CPU 空闲比率，如果系统缓慢而这个值很高，说明系统慢的原因不是 CPU 负载高
wa (iowait): CPU 等待执行 I/O 操作的时间比率，该指标可以用来排查磁盘 I/O 的问题，通常结合 wa 和 id 判断
hi (Hardware IRQ): CPU 处理硬件中断所占时间的比率
si (Software Interrupts): CPU 处理软件中断所占时间的比率
st (steal): 流逝的时间，虚拟机中的其他任务所占 CPU 时间的比率
需要注意的一些情形：

用户进程 us 占比高，I/O 操作 wa 低：说明系统缓慢的原因在于进程占用大量 CPU，通常还会伴有教低的空闲比率 id，说明 CPU 空转时间很少。
I/O 操作 wa 低，空闲比率 id 高：可以排除 CPU 资源瓶颈的可能。
I/O 操作 wa 高：说明 I/O 占用了大量的 CPU 时间，需要检查交换空间的使用，交换空间位于磁盘上，性能远低于内存，当内存耗尽开始使用交换空间时，将会给性能带来严重影响，所以对于性能要求较高的服务器，一般建议关闭交换空间。另一方面，如果内存充足，但 wa 很高，说明需要检查哪个进程占用了大量的 I/O 资源。
更多负载情形，可在实际中灵活判断。

四、iostat 命令

iostat 命令可以查看系统分区的 IO 使用情况

$ iostat \
Linux 2.6.32-573.22.1.el6.x86_64 (sgs02)   01/20/2017     _x86_64_   (1 CPU)\
\
avg-cpu:  %user   %nice %system %iowait  %steal   %idle\
           2.29    0.00    0.25    0.04    0.00   97.41\
\
Device:            tps   Blk_read/s   Blk_wrtn/s   Blk_read   Blk_wrtn\
vda               1.15         3.48        21.88   21016084  131997520
一些值得注意的 IO 指标 :

Device : 磁盘名称
tps : 每秒 I/O 传输请求量
Blk_read/s : 每秒读取多少块，查看块大小可参考命令 tune2fs
Blk_wrtn/s : 每秒写取多少块
Blk_read : 一共读了多少块
–Blk_wrtn : 一共写了多少块
五、iotop 命令

iotop 命令类似于 top 命令，但是显示的是各个进程的 I/O 情况，对于定位 I/O 操作较重的进程有比较大的作用。\

# iotop\
Total DISK READ: 0.00 B/s | Total DISK WRITE: 774.52 K/s\
  TID  PRIO  USER     DISK READ  DISK WRITE  SWAPIN     IO>    COMMAND                                                                \
  272 be/3 root        0.00 B/s    0.00 B/s  0.00 %  4.86 % [jbd2/vda1-8]\
 9072 be/4 mysql       0.00 B/s  268.71 K/s  0.00 %  0.00 % mysqld\
 5058 be/4 lvinkim     0.00 B/s    3.95 K/s  0.00 %  0.00 % php-fpm: pool www\
    1 be/4 root        0.00 B/s    0.00 B/s  0.00 %  0.00 % init
可以看到不同任务的读写强度。

六、sysstat 工具

很多时候当检测到或者知道历史的高负载状况时，可能需要回放历史监控数据，这时 sar 命令就派上用场了，sar 命令同样来自 sysstat 工具包，可以记录系统的 CPU 负载、I/O 状况和内存使用记录，便于历史数据的回放。

sysstat 的配置文件在 /etc/sysconfig/sysstat 文件，历史日志的存放位置为 /var/log/sa\
统计信息都是每 10 分钟记录一次，每天的 23:59 会分割统计文件，这些操作的频率都在 /etc/cron.d/sysstat 文件配置。\

七、sar 命令

使用 sar 命令查看当天 CPU 使用：

$ sar\
Linux 2.6.32-431.23.3.el6.x86_64 (szs01)   01/20/2017     _x86_64_   (1 CPU)\
\
10:50:01 AM     CPU     %user     %nice   %system   %iowait    %steal     %idle\
11:00:01 AM     all      0.45      0.00      0.22      0.40      0.00     98.93\
Average:        all      0.45      0.00      0.22      0.40      0.00     98.93
使用 sar 命令查看当天内存使用：

$ sar -r\
Linux 2.6.32-431.23.3.el6.x86_64 (szs01)   01/20/2017     _x86_64_   (1 CPU)\
\
10:50:01 AM kbmemfree kbmemused  %memused kbbuffers  kbcached  kbcommit   %commit\
11:00:01 AM     41292    459180     91.75     44072    164620    822392    164.32\
Average:        41292    459180     91.75     44072    164620    822392    164.32
使用 sar 命令查看当天 IO 统计记录：

$ sar -b\
Linux 2.6.32-431.23.3.el6.x86_64 (szs01)   01/20/2017     _x86_64_   (1 CPU)\
\
10:50:01 AM       tps      rtps      wtps   bread/s   bwrtn/s\
11:00:01 AM      3.31      2.14      1.17     37.18     16.84\
Average:         3.31      2.14      1.17     37.18     16.84
https://learnku.com/articles/31718
```
### 秘钥登录 
```javascript
ssh-keygen -t rsa -C 'youxiang@aliyun.com'
scp -P <端口号> ~/.ssh/id_rsa.pub <用户名>@<ip地址>:/home/id_rsa.pub
cat /home/id_rsa.pub >> ~/.ssh/authorized_keys

如果在 家目录 没有 .ssh 目录或 authorized_keys 文件，可以创建一下，并授予 authorized_keys 文件 600 权限
ssh root@114.11.11.111
vi ~/.ssh/config

Host            jd            #自定义别名
HostName        114.11.11.110         #替换为你的ssh服务器ip或domain
Port            22             #ssh服务器端口，默认为22
User            root             #ssh服务器用户名
IdentityFile    ~/.ssh/id_rsa    #第一个步骤生成的公钥文件对应的私钥文件
此时就可以使用 ssh jd 进行登录
cd /etc/ssh/

修改 SSH 的配置文件 vi sshd_config

RSAAuthentication yes
PubkeyAuthentication yes
AuthorizedKeysFile      .ssh/authorized_keys
#AuthorizedKeysCommand none
#AuthorizedKeysCommandRunAs nobody

#默认PasswordAuthentication 为yes,即允许密码登录，改为no后，禁止密码登录
PasswordAuthentication no 
重启 ssh 服务

systemctl restart sshd.service
https://learnku.com/articles/30438
```
### 生成二维码
```javascript
第一种方法： qrencode
#安装，记得加epel yum源
[root@localhost ~]# yum install libpng libpng-devel qrencode -y


#格式
Usage: qrencode [OPTION]... [STRING]
OPTIONS：
-o：输出的二维码文件名。如test.png。需要以.png结尾。-表示输出到控制台。
-s：指定图片大小。默认为3个像素。
-t：指定产生的图片类型。默认为PNG。可以是PNG/ANSI/ANSI256/ASCIIi/UTF8等。如果需要输出到控制台，可以用ANSI、ANSI256等
STRING：可以是text、url等


#使用
注：输出的二维码图片大小取决于，内容的多少，且不能换行

# 将“http://jinchuang.org”网址转换为二维码并保存在qrcode.png图片中
[root@localhost ~]# qrencode -o qrcode.png "http://jinchuang.org"

# 在终端下无法查看png图片，所以可以使用ANSI生成
[root@localhost ~]# echo "your input words" | qrencode -o - -t ANSI

# 也可以将需要转换的文字保存为xx.txt文件，之后再转换
[root@localhost ~]# cat xx.txt | qrencode -o - -t ANSI

第二种方法：
[root@localhost ~]# printf "http://jinchuang.org" | curl -F-=\<- qrenco.de 

```
### es Kibana
```javascript

[root@localhost ~]# cd /source
[root@localhost source]# wget https://artifacts.elastic.co/downloads/kibana/kibana-5.6.0-linux-x86_64.tar.gz
[root@localhost source]# tar xf kibana-5.6.0-linux-x86_64.tar.gz  -C /elk/
[root@localhost source]# cd /elk/
[root@localhost elk]# mv kibana-5.6.0-linux-x86_64/ kibana

#修改配置文件
[root@localhost elk]# vim kibana/config/kibana.yml
server.port: 5601
server.host: "0.0.0.0"
elasticsearch.url: "http://127.0.0.1:9200"

#启动
[root@localhost elk]# /elk/kibana/bin/kibana &
[1] 31948
  log   [05:53:04.064] [info][status][plugin:kibana@5.6.0] Status changed from uninitialized to green - Ready
  log   [05:53:04.149] [info][status][plugin:elasticsearch@5.6.0] Status changed from uninitialized to yellow - Waiting for Elasticsearch
  log   [05:53:04.190] [info][status][plugin:console@5.6.0] Status changed from uninitialized to green - Ready
  log   [05:53:04.235] [info][status][plugin:metrics@5.6.0] Status changed from uninitialized to green - Ready
  log   [05:53:04.435] [info][status][plugin:timelion@5.6.0] Status changed from uninitialized to green - Ready
  log   [05:53:04.447] [info][status][plugin:elasticsearch@5.6.0] Status changed from yellow to green - Kibana index ready
  log   [05:53:04.449] [info][listening] Server running at http://0.0.0.0:5601
  log   [05:53:04.452] [info][status][ui settings] Status changed from uninitialized to green - Ready

#查看进程和端口
[root@localhost elk]# ps -ef|grep kibana
root     31948 31038 12 13:52 pts/3    00:00:04 /elk/kibana/bin/../node/bin/node --no-warnings /elk/kibana/bin/../src/cli

[root@localhost elk]# netstat -lntp 
Proto Recv-Q Send-Q Local Address           Foreign Address         State       PID/Program name    
tcp        0      0 0.0.0.0:9100            0.0.0.0:*               LISTEN      28361/grunt         
tcp        0      0 0.0.0.0:22              0.0.0.0:*               LISTEN      14146/sshd      

https://me.jinchuang.org/archives/319.html
```
### 随机数生成
```javascript
(1)  echo $(($RANDOM))          通过系统环境变量

(2)  echo $RANDOM | md5sum|cut -c 1-8

(3)  openssl rand -base64 65         openssl产生随机数

(4)  date +%s%N          通过时间获取随机数

(5)  head /dev/urandom |cksum            设备随机数

(6)  cat /proc/sys/kernel/random/uuid           uuid随机数

(7)  mkpasswd -l 12 -d 5             expect随机数，需要安装expect

```
### Elasticsearch 在 docker 和 CentOS 下的安装教程
```javascript
sudo docker pull docker.elastic.co/elasticsearch/elasticsearch:7.3.1

sudo docker run -p 9200:9200 -p 9300:9300 -e "discovery.type=single-node" docker.elastic.co/elasticsearch/elasticsearch:7.3.1

sudo docker run -itd -p 9200:9200 -p 9300:9300 -e "discovery.type=single-node" docker.elastic.co/elasticsearch/elasticsearch:7.3.1
https://learnku.com/articles/33404
```
### wget 命令提示 “use ‘--no-check-certificate
```javascript
php -r "print_r(openssl_get_cert_locations());"
可以看到证书的默认位置在 /etc/pki/tls/cert.pem，这是在安装 Apache 时自动生成的证书文件。如果你的目录里没有证书文件，使用下面的命令下载一个：

$wget -c https://curl.haxx.se/ca/cacert.pem  /tmp --no-check-certificate
因为我系统上本来就有一个证书文件了，为了不影响原来的，我将新的证书文件下载到 /tmp 目录中。然后设置以下环境变量，使证书只在当前会话生效：

export SSL_CERT_FILE=/tmp/cacert.pem
https://learnku.com/articles/33549

```
### docker
```javascript
如果我们想在一台电脑上搭建各种开发环境：lnmp 环境，java 环境，nodejs，redis 集群，python 开发环境。显然，这些多的开发环境，如果集中在一台机器上构建，会让系统显得复杂，可能还会出现各种版本或依赖之间的不兼容。如果能将这些开发环境都独立开来，各个环境互相独立隔离，但又能互相通讯交互，相当于每个环境都是一个容器，这些容器可以独立提供服务，也能通信交互。

docker 就是这样的容器技术。

用官方术语描述 docker: Docker 是基于 Go 语言实现的开源容器项目，有效地将由单个操作系统管理的资源划分到孤立的组中，以更好地在孤立的组之间平衡有冲突的资源使用需求。

通俗地理解：docker 能让你在一台物理机上构建出很多个轻量极的开发环境。
https://learnku.com/articles/33670#reply108346
```
### xargs 命令
```javascript
echo命令就不接受管道传参。

$ echo "hello world" | echo
xargs命令的作用，是将标准输入转为命令行参数
$ echo "hello world" | xargs echo
hello world
$ echo "one two three" | xargs mkdir

$ xargs
# 等同于
$ xargs echo
-d参数可以更改分隔符。

$ echo -e "a\tb\tc" | xargs -d "\t" echo
a b c

$ echo 'one two three' | xargs -p touch
touch one two three ?...
上面的命令执行以后，会打印出最终要执行的命令，让用户确认。用户输入y以后（大小写皆可），才会真正执行。
xargs特别适合find命令。有些命令（比如rm）一旦参数过多会报错"参数列表过长"，而无法执行，改用xargs就没有这个问题，因为它对每个参数执行一次命令。

$ find . -name "*.txt" | xargs grep "abc"
上面命令找出所有 TXT 文件以后，对每个文件搜索一次是否包含字符串abc
http://www.ruanyifeng.com/blog/2019/08/xargs-tutorial.html
```
### 禁用 eval 函数
```javascript
在 /etc/bashrc 里加入
alias eval = 'echo'

```
###  find 模拟 tree 
```javascript
$ find . -print | sed -e ``'s;[^/]*/;|____;g;s;____|; |;g'


```
### Shell 命令组合
```javascript
统计独立 IP 数量 awk '{print $1}' access.log | sort -n | uniq | wc -l
查看某一时间段的 IP 访问量 grep "05/Apr/2019:0[1-9]" access.log | awk '{print $1}' | sort | uniq -c| sort -nr | wc -l
查看访问最频繁的前 100 个 IP awk '{print $1}' access.log | sort -n | uniq -c | sort -rn | head -n 100
访问 100 次以上的 IP awk '{print $1}' access.log | sort -n | uniq -c | awk '{if($1 > 100) print $0}' | sort -rn
查询某个 IP 的详细访问情况，按访问频率排序 grep '127.0.0.1' access.log | awk '{print $7}' | sort | uniq -c | sort -rn | head -n 100





```
### Crontab 定时任务执行时的环境变量问题
```javascript
不是在 root 用户下安装的 scrapy，是在 crawl 用户下，然后一开始没注意，应该是用 root 用户配置的定时任务，导致定时任务找不到 scrapy，这个可以理解。但是当我在 crawl 用户下，重新配置了爬虫，发现还是报同样的错误。

 
crontab -l  # 通过这个命令，可以查看当前用户下的定时任务
解决办法

后来经过查阅得知，crontab 有自己的环境变量配置，在 /etc/crontab 文件中，并不会自动加载当前用户的环境变量。所以在执行命令之前，应该先配置好环境变量。

所以在 crontab 用户下，执行命令前先载入环境变量，如下。

 
00 10 * * * source $HOME/.bash_profile && $HOME/path/to/script;sh /home/crawl/exec_aqi.sh &  > /dev/null 2>&
如果直接修改 /etc/crontab 文件
SHELL=/bin/bash
PATH=/sbin:/bin:/usr/sbin:/usr/bin
MAILTO=root
00 10 * * * crawl sh /home/crawl/exec_aqi.sh &
https://zcdll.github.io/2018/01/30/own-crontab/
```
### 终端技巧大集合
```javascript
# ‘{}’ 可用于匹配多个模式的文件名 
ls {*.sh,*.py}   #列出所有.sh和.py文件
筛选匹配前后返回的行（例如 “bbo”）

# return also 3 lines after match
grep -A 3 'bbo'

# return also 3 lines before match
grep -B 3 'bbo'

# return also 3 lines before and after match
grep -C 3 'bbo'
删除前 100 行（删除第 1-100 行）

sed 1,100d filename
删除带字符串的行 (例如： bbo)

sed "/bbo/d" filename
- case insensitive:
sed "/bbo/Id" filename
删除空行

sed '/^\s*$/d'

# 或

sed '/^$/d'
查找且删除

find . -name "*.html"|xargs rm

# when using a backtick
rm `find . -name "*.html"`
https://learnku.com/laravel/t/35317#replies
```
### 网络知识之 IP 与子网掩码
```javascript
IP 地址是一种在 Internet 上的给主机编址的方式，也称为网际协议地址。IP 地址是 IP 协议提供的一种统一的地址格式，它为互联网上的每一个网络和每一台主机分配一个逻辑地址，以此来屏蔽物理地址的差异。常见的 IP 地址，分为 IPv4 与 IPv6 两大类。主要介绍的是 IPv4 这一类。 IP 地址是一个 32 位的二进制数，但为了方便记忆，通常被分割为 4 个 "8 位二进制数"，并且用 "点分十进制" 表示为 a.b.c.d 的形式，其中 a,b,c,d 都是 0~255 之间的十进制整数。

IP 地址分为五类，各类可容纳的地址数目不同：

A 类保留给政府机构（0.0.0.0 到 127.255.255.255）

B 类分配给中等规模的公司（128.0.0.0 到 191.255.255.255）

C 类分配给任何需要的人（192.0.0.0 到 223.255.255.255）

D 类用于组播（224.0.0.0---239.255.255.255）

E 类用于实验（240.0.0.0---247.255.255.255）

A、B、C 三类中 IP 地址 = 网络地址 + 主机地址，而 D、E 两类不区分网络地址和主机地址

特殊说明：

（1）A 类中的 10.X.X.X 是私有地址；127.X.X.X 是保留地址

（2）B 类中的 172.16.0.0~172.31.255.255 是私有地址

（3）C 类中的 192.168.X.X 是私有地址
网络地址可以简单理解我们平时常说的网段

主机地址则是在这个网段中不同设备的地址
子网掩码只有一个作用，就是将一个 IP 地址划分成网络地址和主机地址两部分。

（常见的掩码是由一连串 1 + 一连串 0 构成的，不过看网上资料也说 1 和 0 交替也是可以的）

默认分配的子网掩码每段只有 255 或 0

A 类的默认子网掩码　255.0.0.0
B 类的默认子网掩码　255.255.0.0　　
C 类的默认子网掩码　255.255.255.0
子网掩码与 IP 地址一样是 32 位地址，然后将 IP 地址与子网掩码进行与运算即可得到网络地址。

例：

IP地址为192.168.10.2，子网掩码为255.255.255.240。
先将十进制转换成二进制：
IP地址：  11000000 10101000 00001010 00000010
子网掩码： 11111111 11111111 11111111 11110000
进行与运算：－－－－－－－－－－－－－－－－－－－－－－－－－－
          11000000 10101000 00001010 00000000
则可得其网络标识为192.168.10.0，主机标识为2。
3. 掩码的不同表示形式

已经说过了子网掩码也是 32 位的地址，那么开头的 25 怎么转化呢？

25 的意思是网络号为 25，就代表连续的 25 个 1，然后剩下的用 0 补齐

即 11111111 11111111 11111111 10000000

4. 包含的其他信息

还是以这个信息为例：XX.XX.XX.128/25，我们还可以拿到什么信息呢？

（1）主机号：主机号 + 网络号 = 32，32-25=7

（2）网络地址：当 7 位主机号全为 0，也就是 XX.XX.XX.128

（3）广播地址：当 7 位主机号全为 1，也就是 XX.XX.XX.255

（4）可用地址数量：7 位主机号有 2^7 种结果，但是要去掉网络地址和广播地址，即：2^7-2=126 (这个也就是运维所说的一百多个 ip)https://learnku.com/articles/35666 
```
### ssh免密登录漏洞
```javascript
[root@localhost ~]# ll .ssh/
total 42944
-rw-r--r-- 1 root root 43918390 Nov  6  2017 authorized_keys
-rw-r--r-- 1 root root     3415 Apr 26  2019 known_hosts
[root@localhost ~]# cat .ssh/known_hosts
git.coding.net,221.193.246.6 ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQDHOWdwLpkos2CLli6DFvQ36yQE6Pe/PtFp3XwyirfZCIoGWnedaWI8zkJWVCs0wgOB9/urFepTDfV2wN49KGy1sl2/CCDEH2K/zeoEAZlTcBrhU17bwg1yMHCyJ7IM+zdLzItDEKYjgoWqVdUGK1dXQQlwt7GP4W7HqffelQQoVxOMoZ5N50MzD+nvV4y8iq0KwDQNy62iU4hui9ajCSVUDLu/06ucd5IojSI9keRIYAXvQf52TJ5EbvoBggp9RhjuWNEG8IhnPP6rzPS11Ocmwg/Hs
打开 vi authorized_keys 并没有任何东西。然后我顺带把其它 /root/.ssh/ 下的四个文件都翻了一遍。
才发现 known_hosts 文件中多了两个 IP 地址为新加坡的 ssh key  https://learnku.com/articles/35888
```
### crontab 指定用户
```javascript
直接在 /etc/crontab 中编辑定时任务即可，加上用户名
SHELL=/bin/sh
PATH=/usr/local/sbin:/usr/local/bin:/sbin:/bin:/usr/sbin:/usr/bin

# Example of job definition:
# .---------------- minute (0 - 59)
# |  .------------- hour (0 - 23)
# |  |  .---------- day of month (1 - 31)
# |  |  |  .------- month (1 - 12) OR jan,feb,mar,apr ...
# |  |  |  |  .---- day of week (0 - 6) (Sunday=0 or 7) OR sun,mon,tue,wed,thu,fri,sat
# |  |  |  |  |
# *  *  *  *  * user-name command to be executed
17 *    * * *   root    cd / && run-parts --report /etc/cron.hourly
25 6    * * *   root    test -x /usr/sbin/anacron || ( cd / && run-parts --report /etc/cron.daily )
47 6    * * 7   root    test -x /usr/sbin/anacron || ( cd / && run-parts --report /etc/cron.weekly )
52 6    1 * *   root    test -x /usr/sbin/anacron || ( cd / && run-parts --report /etc/cron.monthly )
#

# cron
* * * * *  www-data flock /tmp/flock1.lock -c 'timeout 200 /usr/local/bin/php /var/www/html/laravel/artisan command >> /home/log/laravel.log 2>&1'
flock 用来防止重复执行，起到原子锁作用
                                                                                                                                                  timeout 表示这个脚本执行过长，咱就干死它，可以有效避免各种循环或长时间占用问题
https://learnku.com/articles/35948

* * * * * flock -xn /tmp/test.lock -c "timeout 200 php /home/app/email.php >> /home/log/test.log 2>&1" 
想 10s 执行一次怎么办？

* * * * * php /home/app/email.php >> /home/log/test.log 2>&1
* * * * * ( sleep 10 ; php /home/app/email.php >> /home/log/test.log 2>&1 )
* * * * * ( sleep 20 ; php /home/app/email.php >> /home/log/test.log 2>&1 )
* * * * * ( sleep 30 ; php /home/app/email.php >> /home/log/test.log 2>&1 )
* * * * * ( sleep 40 ; php /home/app/email.php >> /home/log/test.log 2>&1 )
* * * * * ( sleep 50 ; php /home/app/email.php >> /home/log/test.log 2>&1 )
```
### >  >>
```javascript
> 表示覆盖追加
>> 表示尾部追加
这两个管道操作符，在执行期间发生错误时，是不会将错误输出写入后面的「文件」中的。
在 Linux 系统中 0、1、2 分别表示不同的设备类型，其中

0 标准输入设备，指键盘
1 标准正确输出设备
2 标准错误输出设备
php artisan command >> /home/log/laravel.log 2>&1'
上面命令的意思是将 php artisan command 的 标准正确输出 重定向到 laravel.log 文件。
而后面的 2>&1 是表示将标注错误输出重定向到标准正确输出。

从而达到错误输出和正确输出都记录在 laravel.log 文件中。

```
### 内网穿透
```javascript
https://serveo.net/
λ ssh -R 80:localhost:3000 serveo.net
Forwarding HTTP traffic from https://habeo.serveo.net
Press g to start a GUI session and ctrl-c to quit.

```
### ab 压力测试
```javascript
ab -n 2000 -c 1000 http://www.xxx.com/index.php
需要调整内核参数以支持端口重用
假如我现在使用的是 Linux 服务器，找到如下文件
sudo vim /etc/sysctl.conf
添加如下内容

net.ipv4.tcp_syncookies = 1
net.ipv4.tcp_tw_reuse = 1
net.ipv4.tcp_tw_recycle = 1
net.ipv4.tcp_fin_timeout = 30
kernel.printk = 7 4 1 7
运行 sudo sysctl –p 生效
https://learnku.com/articles/4765/simple-primary-stress-test
```
### https 证书注册工具
```
apt-get install certbot python-certbot-nginx
certbot --nginx
certbot renew --dry-run

https://certbot.eff.org/
```

[配置安全的 SSH 服务](https://learnku.com/linux/t/36120)

[使用 fail2ban 来防范 SSH 暴力破解](https://learnku.com/linux/t/36233)

[在线crontab](https://crontab.guru/)

[docker 快速搭建稳定安全的开发/生产环境](https://github.com/jianyan74/dockerfiles)

[windows 10 WSL编码](https://gleehub.com/program/wsl-xia-you-ya-di-coding.html)

[初识 Shell](https://learnku.com/articles/33469)

[html 转 pdf 命令行工具 wkhtmltopdf ](http://einverne.github.io/post/2019/01/html-to-pdf.html)

[Centos7 搭建 Nextcloud个人网盘](https://me.jinchuang.org/archives/301.html)

[三十分钟学会sed](https://github.com/mylxsw/growing-up/blob/master/doc/%E4%B8%89%E5%8D%81%E5%88%86%E9%92%9F%E5%AD%A6%E4%BC%9ASED.md)

[Linux工具快速教程](https://linuxtools-rst.readthedocs.io/zh_CN/latest/index.html)

[看例子学sed](http://qinghua.github.io/sed/)

[工作中常用的 Linux 命令](https://michael728.github.io/2018/07/05/linux-useful-commands-in-work/)

[工作中常用的 Shell 命令及技巧](https://michael728.github.io/2019/04/14/linux-useful-shell-commands-in-work/)

[PHPer 必知必会的 Linux 命令](https://linux.hellocode.name/user-group.html)

[Linux工具快速教程](https://linuxtools-rst.readthedocs.io/zh_CN/latest/index.html#)

[你可能不知道的shell技巧](https://segmentfault.com/a/1190000016648034)

[wget的15个震撼的例子](https://neuqzxy.github.io/2017/07/08/wget%E7%9A%8415%E4%B8%AA%E9%9C%87%E6%92%BC%E7%9A%84%E4%BE%8B%E5%AD%90/)

[Linux 踩坑记](https://www.restran.net/2015/10/19/linux-practice-notes/)

[PHPer 必知必会的 Linux 命令](https://github.com/Nick233333/phper-linux-gitbook)

[命令行的艺术](https://github.com/jlevy/the-art-of-command-line)

[Nginx 学习笔记时序图](https://www.njphper.com/posts/680ebdf2.html)

[Windows 10 安装体验](https://learnku.com/articles/28500)

[打造高效的工作环境 – SHELL 篇https://github.com/coolshellx/articles](https://coolshell.cn/articles/19219.html)


[工作中常用的 Linux 命令](https://michael728.github.io/2018/07/05/linux-useful-commands-in-work/)