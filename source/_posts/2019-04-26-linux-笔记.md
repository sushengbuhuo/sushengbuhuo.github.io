---
title: linux 笔记
date: 2019-04-26 16:54:15
tags:
- linux
---
### 磁盘空间不足
```javascript
df命令查看当前计算器磁盘空闲情况
 df -a
 从根目录下开始使用du命令查找出空间占用最大的文件
  du -sh /*命令一路追查
 [root@test-os testuser]# df -h   ###物理磁盘空间 查看所有block使用情况
 Filesystem      Size  Used Avail Use% Mounted on
 /dev/sda3       8.8G  8.8G     0 100% /
 tmpfs           931M     0  931M   0% /dev/shm
 /dev/sda1       190M   40M  141M  22% /boot
 [root@test-os testuser]# du -sh /usr/* |grep G  ###查找大文件
 7.3G    /usr/local
 [root@test-os testuser]# du -sh /usr/local/* |grep G
 7.3G    /usr/local/bin
 [root@test-os testuser]# du -sh /usr/local/bin/* |grep G
 7.3G    /usr/local/bin/1g
 
 [root@test-os testuser]# rm -f /usr/local/bin/1g  ###删除大文件
有些文件删除时还被其它进程占用，此时文件并未真正删除，只是标记为 deleted，只有进程结束后才会将文件真正从磁盘中清除。
 [root@test-os ~]# lsof |grep deleted 
 rsyslogd   1250      root    1w      REG                8,3 4888889358     140789 /var/log/messages (deleted)
 
 [root@test-os ~]# #lsof 显示出系统中被打开的文件 
 [root@test-os ~]# #第一列 软件/服务的名称
 [root@test-os ~]# #第八列 文件的大小 
 [root@test-os ~]# #第10列 文件的名字
 [root@test-os ~]# #第11列 标记（硬链接数为0 进程调用数不为零 就会有 delete)
 
 ####重启对应的服务 释放磁盘空间 
 [root@test-os ~]# /etc/init.d/rsyslog restart 
 --------------------- 
 [root@test-os ~]# df -h
 Filesystem      Size  Used Avail Use% Mounted on
 /dev/sda3       8.8G  1.5G  6.9G  18% /
 tmpfs           931M     0  931M   0% /dev/shm
 /dev/sda1       190M   40M  141M  22% /boot
 /tmp/1m        1003K   19K  933K   2% /app/logs
 --------------------- 
 # df -ih 节点磁盘空间
 Filesystem Inodes IUsed IFree IUse% Mounted on
 /dev/vda1 1.9M 299K 1.6M 17% /
 udev  123K 299 123K 1% /dev
 tmpfs  126K 249 125K 1% /run
 tmpfs  126K 4 126K 1% /run/lock
 tmpfs  126K 2 126K 1% /run/shm
 可以看到，inode 区域只被占用了一小部分，还有大量的空间未使用，所以也不是 inode 区域被占满的问题。
 查看哪个目录占用过大：
 
 cd /;du  -sh ./* |sort -nr|more
 发现 /var/spool/postfix/maildrop 这个目录占用了12G 多的空间
 删除这个目录下的内容(通过管道的方式删除,避免参数过长导致无法执行)：
 
 ls | xargs rm -f
 lsof test.log
 这命令只能在文件被写入的时候才能显示内容，最后虽然得到了个进程号，但是因为写完进程就关闭了，所以还是查不到
 
    for i in /home/*; do echo $i; find $i |wc -l; done
 
    通过该命令可以查看每个用户home下inode的占用情况。如果某个目录下的inode很大，那就是问题所在了。
 
```
### git push 报错 fatal: HttpRequestException encountered.
```javascript
Github 禁用了TLS v1.0 and v1.1，必须更新Windows的git凭证管理器

https://github.com/Microsoft/Git-Credential-Manager-for-Windows/releases/tag/v1.18.2

下载并安装后即可解决
 
```
### pip install 失败
```javascript

 pip install myqr
Collecting myqr
  Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProxyError('Cannot connect to proxy.', NewConnectionError('<pip._vendor.urllib3.connection.VerifiedHTTPSConnection object at 0x03B22330>: Failed to establish a new connection: [WinError 10061] 由于目
标计算机积极拒绝，无法连接。'))': /simple/myqr/
打开Internet选项，选择连接–局域网设置  全部取消勾选，问题解决
https://blog.csdn.net/u010784236/article/details/51820284
```
### awk
```javascript
$ echo 'this is a test' | awk '{print $0}'
$ awk -F ':' '{ print $1 }' demo.txt
$(NF-1) 代表倒数第二个字段。
 
$ awk -F ':' '{print $1, $(NF-1)}' demo.txt
 NR 表示当前处理的是第几行。
 
$ awk -F ':' '{print NR ") " $1}' demo.txt
awk -F ':' '{ print toupper($1) }' demo.txt
awk -F ':' '/usr/ {print $1}' demo.txt #awk ‘条件 动作’ 文件名  print 命令前面是一个正则表达式，只输出包含 usr 的行
awk -F ':' 'NR % 2 == 1 {print $1}' demo.txt 输出奇数行
awk -F ':' '{if ($1 > "m") print $1}' demo.txt
$ awk -F ':' '{if ($1 > "m") print $1; else print "---"}' demo.txt
```
### 批量删除 .DS_Store 文件
`find /home/path -name ".DS_Store" -type f -delete`

### 查看硬盘及内存空间
```javascript
 
# 查看内存及swap大小
free -m
# 查看当前文件夹下所有文件大小（包括子文件夹）
du -sh
# 查看指定文件夹下所有文件大小
du -h /tmp
# 查看tmp目录(包含子目录)的大小
du -ah /tmp

# 查看指定文件夹大小
du -hs ftp
# 查看磁盘剩余空间
df -hl
# 查看每个根路径的分区大小
df -h
# 返回该目录的大小
du -sh [目录名]
# 返回该文件夹总M数
du -sm [文件夹]
```
### 统计文件或目录的个数
```javascript
# 统计文件夹下文件的个数
ls -l | grep '^-' | wc -l
# 统计文件夹下目录的个数
ls -l | grep '^d' | wc -l
# 统计文件夹下文件的个数(包括子文件夹里的)
ls -lR | grep '^-' | wc -l
# 统计文件夹下目录的个数(包括子文件夹里的)
ls -lR | grep '^d' | wc -l
# 统计/var/www目录下的所有py文件
ls -l /var/www | grep py | wc -l
# 统计/var/www目录下(包括子文件夹里的)的所有py文件
ls -lR /var/www | grep py | wc -l
```
### 查看CPU和内存占用
```javascript
# CPU占用最多的前10个进程： 
ps auxw|head -1;ps auxw|sort -rn -k3|head -10 
# 内存消耗最多的前10个进程 
ps auxw|head -1;ps auxw|sort -rn -k4|head -10 
# 虚拟内存使用最多的前10个进程 
ps auxw|head -1;ps auxw|sort -rn -k5|head -10
 按内存占用对进程排序
ps auxw --sort=rss
# 按CPU占用对进程排序
ps auxw --sort=%cpu

查看所有运行的进程
ps -A
```
### curl
```javascript
强制指定本地端口
curl --local-port 51 http://web.example.com

# 查看连接的详细信息
# --trace-time 跟踪/详细输出时，添加时间戳
curl -Sv --trace-time http://web.example.com

```
### 连接你服务器 top10 用户端的 IP 地址
```javascript
netstat -nat | awk '{print $5}' | awk -F ':' '{print $1}' | sort | uniq -c | sort -rn | head -n 10


```
### 最常用的10个命令
```javascript
cat .bash_history | sort | uniq -c | sort -rn | head -n 10 (or cat .zhistory | sort | uniq -c | sort -rn | head -n 10


```
### alias
```javascript
alias nis="npm install --save "
alias svim='sudo vim'
alias mkcd='foo(){ mkdir -p "$1"; cd "$1" }; foo '
alias install='sudo apt get install'
alias update='sudo apt-get update; sudo apt-get upgrade'
alias ..="cd .."
alias ...="cd ..; cd .."
alias www='python -m SimpleHTTPServer 8000'
alias sock5='ssh -D 8080 -q -C -N -f user@your.server'
```
### wget
```javascript
wget http://www.openss7.org/repos/tarballs/strx25-0.9.2.1.ta
$ wget -b http://www.openss7.org/repos/tarballs/strx25-0.9.2.1.tar.bz2
Continuing in background, pid 1984.
Output will be written to `wget-log'.
wget -i download-file-list.txt


```
### 防火墙
```javascript
sudo firewall-cmd --zone=public --add-port=60001/udp --permanent
sudo firewall-cmd --reload
#之后检查新的防火墙规则
firewall-cmd --list-all

//临时关闭防火墙,重启后会重新自动打开
systemctl restart firewalld
//检查防火墙状态
firewall-cmd --state
firewall-cmd --list-all
//Disable firewall
systemctl disable firewalld
systemctl stop firewalld
systemctl status firewalld
//Enable firewall
systemctl enable firewalld
systemctl start firewalld
systemctl status firewalld
```
### 显示 Path 环境变量
```javascript
 $ echo $PATH | tr : \\n
/data2/node-v6.11.0-linux-x64//bin
/usr/bin
/bin
/usr/sbin
/sbin
/usr/local/bin
/usr/local/sbin
/data0/opt/python27/bin

```
### 判断字符串包含
```javascript
if [[ $tar =~ tar.gz ]];then echo "包含";fi
```
### 快速修改后缀名字
```javascript
ll
CentOS-base.repo.repo.bak
epel.repo.repo.bak

ls *.bak|awk -F. '{print $1}'|xargs -t -i mv {}.repo.repo.bak {}.repo
```
### 数值排序
```javascript
sort -t ":" -k 3 -n /etc/passwd
```
### 清理httpd服务日志超过3天的内容
```javascript
0 5 * * * /usr/bin/find /var/log/httpd/ -type f -mtime +3 -exec rm -rf {} \;
```
### awk获取json
```javascript
{"name": "michael", "sex": "male", "pkg_url": "www.github.com", "number": "888"}

pkg_url=$(echo $env | awk -F "pkg_url\": \"" '{print $2}' | awk -F "\"," '{print $1}')
echo $pkg_url
www.github.com
```
### cpu
```javascript
查看 CPU 的型号

 cat /proc/cpuinfo | grep 'model name' | sort | uniq
查看 CPU 颗数

实际 Server 中插槽上的 CPU 个数，物理 cpu 数量，可以数不重复的 physical id 个数。

cat /proc/cpuinfo | grep 'physical id' | sort | uniq | wc -l
查看 CPU 核数

一颗 CPU 上面能处理数据的芯片组的数量。

cat /proc/cpuinfo |grep "cores"|uniq|awk '{print $4}'
top 命令查询出来的就是逻辑 CPU 的数量。

cat /proc/cpuinfo |grep "processor"|wc -l
https://learnku.com/articles/32681
```
### 查看系统负载
```javascript
$ uptime\
16:33:56 up 69 days,  5:10,  1 user,  load average: 0.14, 0.24, 0.29
以上信息的解析如下：

16:33:56 : 当前时间
up 69 days, 5:10 : 系统运行了 69 天 5 小时 10 分
1 user : 当前有 1 个用户登录了系统 load average: 0.14, 0.24, 0.29 : 系统在过去 1 分钟内，5 分钟内，15 分钟内的平均负载
load average: 0.14, 0.24, 0.29 : 系统在过去 1 分钟内，5 分钟内，15 分钟内的平均负载
平均负载解析

查看逻辑 CPU 核心数：

$ grep 'model name' /proc/cpuinfo | wc -l\
1\
运行结果表示，有 1 个逻辑 CPU 核心。以 1 个 CPU 核心为例，假设 CPU 每分钟最多处理 100 个进程 –

load=0，没有进程需要 CPU
load=0.5，CPU 处理了 50 个进程
load=1, CPU 处理了 100 个进程，这时 CPU 已被占满，但系统还是能顺畅运作的
load=1.5, CPU 处理了 100 个进程，还有 50 个进程正在排除等着 CPU 处理，这时，CPU 已经超负荷工作了
为了系统顺畅运行，load 值最好不要超过 1.0，这样就没有进程需要等待了，所有进程都能第一时间得到处理。\
很显然，1.0 是一个关键值，超过这个值，系统就不在最佳状态了。 一般 0.7 是一个比较理想的值。\
另外，load 值的健康状态还跟系统 CPU 核心数相关，如果 CPU 核心数为 2，那么 load 值健康值应该为 2，以此类推。 \
评价系统的负载一般采用 15 分钟内的那个平均负载值。

二、w 命令

$ w\
 17:47:40 up 69 days,  6:24,  1 user,  load average: 0.46, 0.26, 0.25\
USER     TTY      FROM              LOGIN@   IDLE   JCPU   PCPU WHAT\
lvinkim  pts/0    14.18.144.2      15:55    0.00s  0.02s  0.00s w
第 1 行：与 uptime 一相同。 \
第 2 行以下，当前登录用户的列表。

三、top 命令

$ top\
top - 17:51:23 up 69 days,  6:28,  1 user,  load average: 0.31, 0.30, 0.26\
Tasks:  99 total,   1 running,  98 sleeping,   0 stopped,   0 zombie\
Cpu(s):  2.3%us,  0.2%sy,  0.0%ni, 97.4%id,  0.0%wa,  0.0%hi,  0.0%si,  0.0%st\
Mem:   1922244k total,  1737480k used,   184764k free,   208576k buffers\
Swap:        0k total,        0k used,        0k free,   466732k cached\
\
  PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  COMMAND                                                                \
    1 root      20   0 19232 1004  708 S  0.0  0.1   0:01.17 init                                                                    \
    2 root      20   0     0    0    0 S  0.0  0.0   0:00.01 kthreadd                                                                \
...
第 1 行：与 uptime 一相同。

第 2 行：进程数信息。

Tasks: 99 total : 总共有 99 个进程
1 running : 1 个进程正在占用 CPU
98 sleeping : 98 个睡眠进程
0 stopped : 0 个停止的进程
0 zombie : 0 个僵尸进程
第 3 行 : CPU 使用率

us (user): 非 nice 用户进程占用 CPU 的比率
sy (system): 内核、内核进程占用 CPU 的比率
ni (nice): 用户进程空间内改变过优先级的进程占用 CPU 比率
id (idle): CPU 空闲比率，如果系统缓慢而这个值很高，说明系统慢的原因不是 CPU 负载高
wa (iowait): CPU 等待执行 I/O 操作的时间比率，该指标可以用来排查磁盘 I/O 的问题，通常结合 wa 和 id 判断
hi (Hardware IRQ): CPU 处理硬件中断所占时间的比率
si (Software Interrupts): CPU 处理软件中断所占时间的比率
st (steal): 流逝的时间，虚拟机中的其他任务所占 CPU 时间的比率
需要注意的一些情形：

用户进程 us 占比高，I/O 操作 wa 低：说明系统缓慢的原因在于进程占用大量 CPU，通常还会伴有教低的空闲比率 id，说明 CPU 空转时间很少。
I/O 操作 wa 低，空闲比率 id 高：可以排除 CPU 资源瓶颈的可能。
I/O 操作 wa 高：说明 I/O 占用了大量的 CPU 时间，需要检查交换空间的使用，交换空间位于磁盘上，性能远低于内存，当内存耗尽开始使用交换空间时，将会给性能带来严重影响，所以对于性能要求较高的服务器，一般建议关闭交换空间。另一方面，如果内存充足，但 wa 很高，说明需要检查哪个进程占用了大量的 I/O 资源。
更多负载情形，可在实际中灵活判断。

四、iostat 命令

iostat 命令可以查看系统分区的 IO 使用情况

$ iostat \
Linux 2.6.32-573.22.1.el6.x86_64 (sgs02)   01/20/2017     _x86_64_   (1 CPU)\
\
avg-cpu:  %user   %nice %system %iowait  %steal   %idle\
           2.29    0.00    0.25    0.04    0.00   97.41\
\
Device:            tps   Blk_read/s   Blk_wrtn/s   Blk_read   Blk_wrtn\
vda               1.15         3.48        21.88   21016084  131997520
一些值得注意的 IO 指标 :

Device : 磁盘名称
tps : 每秒 I/O 传输请求量
Blk_read/s : 每秒读取多少块，查看块大小可参考命令 tune2fs
Blk_wrtn/s : 每秒写取多少块
Blk_read : 一共读了多少块
–Blk_wrtn : 一共写了多少块
五、iotop 命令

iotop 命令类似于 top 命令，但是显示的是各个进程的 I/O 情况，对于定位 I/O 操作较重的进程有比较大的作用。\

# iotop\
Total DISK READ: 0.00 B/s | Total DISK WRITE: 774.52 K/s\
  TID  PRIO  USER     DISK READ  DISK WRITE  SWAPIN     IO>    COMMAND                                                                \
  272 be/3 root        0.00 B/s    0.00 B/s  0.00 %  4.86 % [jbd2/vda1-8]\
 9072 be/4 mysql       0.00 B/s  268.71 K/s  0.00 %  0.00 % mysqld\
 5058 be/4 lvinkim     0.00 B/s    3.95 K/s  0.00 %  0.00 % php-fpm: pool www\
    1 be/4 root        0.00 B/s    0.00 B/s  0.00 %  0.00 % init
可以看到不同任务的读写强度。

六、sysstat 工具

很多时候当检测到或者知道历史的高负载状况时，可能需要回放历史监控数据，这时 sar 命令就派上用场了，sar 命令同样来自 sysstat 工具包，可以记录系统的 CPU 负载、I/O 状况和内存使用记录，便于历史数据的回放。

sysstat 的配置文件在 /etc/sysconfig/sysstat 文件，历史日志的存放位置为 /var/log/sa\
统计信息都是每 10 分钟记录一次，每天的 23:59 会分割统计文件，这些操作的频率都在 /etc/cron.d/sysstat 文件配置。\

七、sar 命令

使用 sar 命令查看当天 CPU 使用：

$ sar\
Linux 2.6.32-431.23.3.el6.x86_64 (szs01)   01/20/2017     _x86_64_   (1 CPU)\
\
10:50:01 AM     CPU     %user     %nice   %system   %iowait    %steal     %idle\
11:00:01 AM     all      0.45      0.00      0.22      0.40      0.00     98.93\
Average:        all      0.45      0.00      0.22      0.40      0.00     98.93
使用 sar 命令查看当天内存使用：

$ sar -r\
Linux 2.6.32-431.23.3.el6.x86_64 (szs01)   01/20/2017     _x86_64_   (1 CPU)\
\
10:50:01 AM kbmemfree kbmemused  %memused kbbuffers  kbcached  kbcommit   %commit\
11:00:01 AM     41292    459180     91.75     44072    164620    822392    164.32\
Average:        41292    459180     91.75     44072    164620    822392    164.32
使用 sar 命令查看当天 IO 统计记录：

$ sar -b\
Linux 2.6.32-431.23.3.el6.x86_64 (szs01)   01/20/2017     _x86_64_   (1 CPU)\
\
10:50:01 AM       tps      rtps      wtps   bread/s   bwrtn/s\
11:00:01 AM      3.31      2.14      1.17     37.18     16.84\
Average:         3.31      2.14      1.17     37.18     16.84
https://learnku.com/articles/31718
```
### 秘钥登录 
```javascript
ssh-keygen -t rsa -C 'youxiang@aliyun.com'
scp -P <端口号> ~/.ssh/id_rsa.pub <用户名>@<ip地址>:/home/id_rsa.pub
cat /home/id_rsa.pub >> ~/.ssh/authorized_keys

如果在 家目录 没有 .ssh 目录或 authorized_keys 文件，可以创建一下，并授予 authorized_keys 文件 600 权限
ssh root@114.11.11.111
vi ~/.ssh/config

Host            jd            #自定义别名
HostName        114.11.11.110         #替换为你的ssh服务器ip或domain
Port            22             #ssh服务器端口，默认为22
User            root             #ssh服务器用户名
IdentityFile    ~/.ssh/id_rsa    #第一个步骤生成的公钥文件对应的私钥文件
此时就可以使用 ssh jd 进行登录
cd /etc/ssh/

修改 SSH 的配置文件 vi sshd_config

RSAAuthentication yes
PubkeyAuthentication yes
AuthorizedKeysFile      .ssh/authorized_keys
#AuthorizedKeysCommand none
#AuthorizedKeysCommandRunAs nobody

#默认PasswordAuthentication 为yes,即允许密码登录，改为no后，禁止密码登录
PasswordAuthentication no 
重启 ssh 服务

systemctl restart sshd.service
https://learnku.com/articles/30438
```
### 生成二维码
```javascript
第一种方法： qrencode
#安装，记得加epel yum源
[root@localhost ~]# yum install libpng libpng-devel qrencode -y


#格式
Usage: qrencode [OPTION]... [STRING]
OPTIONS：
-o：输出的二维码文件名。如test.png。需要以.png结尾。-表示输出到控制台。
-s：指定图片大小。默认为3个像素。
-t：指定产生的图片类型。默认为PNG。可以是PNG/ANSI/ANSI256/ASCIIi/UTF8等。如果需要输出到控制台，可以用ANSI、ANSI256等
STRING：可以是text、url等


#使用
注：输出的二维码图片大小取决于，内容的多少，且不能换行

# 将“http://jinchuang.org”网址转换为二维码并保存在qrcode.png图片中
[root@localhost ~]# qrencode -o qrcode.png "http://jinchuang.org"

# 在终端下无法查看png图片，所以可以使用ANSI生成
[root@localhost ~]# echo "your input words" | qrencode -o - -t ANSI

# 也可以将需要转换的文字保存为xx.txt文件，之后再转换
[root@localhost ~]# cat xx.txt | qrencode -o - -t ANSI

第二种方法：
[root@localhost ~]# printf "http://jinchuang.org" | curl -F-=\<- qrenco.de 

```
### es Kibana
```javascript

[root@localhost ~]# cd /source
[root@localhost source]# wget https://artifacts.elastic.co/downloads/kibana/kibana-5.6.0-linux-x86_64.tar.gz
[root@localhost source]# tar xf kibana-5.6.0-linux-x86_64.tar.gz  -C /elk/
[root@localhost source]# cd /elk/
[root@localhost elk]# mv kibana-5.6.0-linux-x86_64/ kibana

#修改配置文件
[root@localhost elk]# vim kibana/config/kibana.yml
server.port: 5601
server.host: "0.0.0.0"
elasticsearch.url: "http://127.0.0.1:9200"

#启动
[root@localhost elk]# /elk/kibana/bin/kibana &
[1] 31948
  log   [05:53:04.064] [info][status][plugin:kibana@5.6.0] Status changed from uninitialized to green - Ready
  log   [05:53:04.149] [info][status][plugin:elasticsearch@5.6.0] Status changed from uninitialized to yellow - Waiting for Elasticsearch
  log   [05:53:04.190] [info][status][plugin:console@5.6.0] Status changed from uninitialized to green - Ready
  log   [05:53:04.235] [info][status][plugin:metrics@5.6.0] Status changed from uninitialized to green - Ready
  log   [05:53:04.435] [info][status][plugin:timelion@5.6.0] Status changed from uninitialized to green - Ready
  log   [05:53:04.447] [info][status][plugin:elasticsearch@5.6.0] Status changed from yellow to green - Kibana index ready
  log   [05:53:04.449] [info][listening] Server running at http://0.0.0.0:5601
  log   [05:53:04.452] [info][status][ui settings] Status changed from uninitialized to green - Ready

#查看进程和端口
[root@localhost elk]# ps -ef|grep kibana
root     31948 31038 12 13:52 pts/3    00:00:04 /elk/kibana/bin/../node/bin/node --no-warnings /elk/kibana/bin/../src/cli

[root@localhost elk]# netstat -lntp 
Proto Recv-Q Send-Q Local Address           Foreign Address         State       PID/Program name    
tcp        0      0 0.0.0.0:9100            0.0.0.0:*               LISTEN      28361/grunt         
tcp        0      0 0.0.0.0:22              0.0.0.0:*               LISTEN      14146/sshd      

https://me.jinchuang.org/archives/319.html
```
### 随机数生成
```javascript
(1)  echo $(($RANDOM))          通过系统环境变量

(2)  echo $RANDOM | md5sum|cut -c 1-8

(3)  openssl rand -base64 65         openssl产生随机数

(4)  date +%s%N          通过时间获取随机数

(5)  head /dev/urandom |cksum            设备随机数

(6)  cat /proc/sys/kernel/random/uuid           uuid随机数

(7)  mkpasswd -l 12 -d 5             expect随机数，需要安装expect

```
### Elasticsearch 在 docker 和 CentOS 下的安装教程
```javascript
sudo docker pull docker.elastic.co/elasticsearch/elasticsearch:7.3.1

sudo docker run -p 9200:9200 -p 9300:9300 -e "discovery.type=single-node" docker.elastic.co/elasticsearch/elasticsearch:7.3.1

sudo docker run -itd -p 9200:9200 -p 9300:9300 -e "discovery.type=single-node" docker.elastic.co/elasticsearch/elasticsearch:7.3.1
https://learnku.com/articles/33404
```
### wget 命令提示 “use ‘--no-check-certificate
```javascript
php -r "print_r(openssl_get_cert_locations());"
可以看到证书的默认位置在 /etc/pki/tls/cert.pem，这是在安装 Apache 时自动生成的证书文件。如果你的目录里没有证书文件，使用下面的命令下载一个：

$wget -c https://curl.haxx.se/ca/cacert.pem  /tmp --no-check-certificate
因为我系统上本来就有一个证书文件了，为了不影响原来的，我将新的证书文件下载到 /tmp 目录中。然后设置以下环境变量，使证书只在当前会话生效：

export SSL_CERT_FILE=/tmp/cacert.pem
https://learnku.com/articles/33549

```
### docker
```javascript
如果我们想在一台电脑上搭建各种开发环境：lnmp 环境，java 环境，nodejs，redis 集群，python 开发环境。显然，这些多的开发环境，如果集中在一台机器上构建，会让系统显得复杂，可能还会出现各种版本或依赖之间的不兼容。如果能将这些开发环境都独立开来，各个环境互相独立隔离，但又能互相通讯交互，相当于每个环境都是一个容器，这些容器可以独立提供服务，也能通信交互。

docker 就是这样的容器技术。

用官方术语描述 docker: Docker 是基于 Go 语言实现的开源容器项目，有效地将由单个操作系统管理的资源划分到孤立的组中，以更好地在孤立的组之间平衡有冲突的资源使用需求。

通俗地理解：docker 能让你在一台物理机上构建出很多个轻量极的开发环境。
https://learnku.com/articles/33670#reply108346
```
### xargs 命令
```javascript
echo命令就不接受管道传参。

$ echo "hello world" | echo
xargs命令的作用，是将标准输入转为命令行参数
$ echo "hello world" | xargs echo
hello world
$ echo "one two three" | xargs mkdir

$ xargs
# 等同于
$ xargs echo
-d参数可以更改分隔符。

$ echo -e "a\tb\tc" | xargs -d "\t" echo
a b c

$ echo 'one two three' | xargs -p touch
touch one two three ?...
上面的命令执行以后，会打印出最终要执行的命令，让用户确认。用户输入y以后（大小写皆可），才会真正执行。
xargs特别适合find命令。有些命令（比如rm）一旦参数过多会报错"参数列表过长"，而无法执行，改用xargs就没有这个问题，因为它对每个参数执行一次命令。

$ find . -name "*.txt" | xargs grep "abc"
上面命令找出所有 TXT 文件以后，对每个文件搜索一次是否包含字符串abc
http://www.ruanyifeng.com/blog/2019/08/xargs-tutorial.html
```
### 禁用 eval 函数
```javascript
在 /etc/bashrc 里加入
alias eval = 'echo'

```
###  find 模拟 tree 
```javascript
$ find . -print | sed -e ``'s;[^/]*/;|____;g;s;____|; |;g'


```
### Shell 命令组合
```javascript
统计独立 IP 数量 awk '{print $1}' access.log | sort -n | uniq | wc -l
查看某一时间段的 IP 访问量 grep "05/Apr/2019:0[1-9]" access.log | awk '{print $1}' | sort | uniq -c| sort -nr | wc -l
查看访问最频繁的前 100 个 IP awk '{print $1}' access.log | sort -n | uniq -c | sort -rn | head -n 100
访问 100 次以上的 IP awk '{print $1}' access.log | sort -n | uniq -c | awk '{if($1 > 100) print $0}' | sort -rn
查询某个 IP 的详细访问情况，按访问频率排序 grep '127.0.0.1' access.log | awk '{print $7}' | sort | uniq -c | sort -rn | head -n 100





```
### Crontab 定时任务执行时的环境变量问题
```javascript
不是在 root 用户下安装的 scrapy，是在 crawl 用户下，然后一开始没注意，应该是用 root 用户配置的定时任务，导致定时任务找不到 scrapy，这个可以理解。但是当我在 crawl 用户下，重新配置了爬虫，发现还是报同样的错误。

 
crontab -l  # 通过这个命令，可以查看当前用户下的定时任务
解决办法

后来经过查阅得知，crontab 有自己的环境变量配置，在 /etc/crontab 文件中，并不会自动加载当前用户的环境变量。所以在执行命令之前，应该先配置好环境变量。

所以在 crontab 用户下，执行命令前先载入环境变量，如下。

 
00 10 * * * source $HOME/.bash_profile && $HOME/path/to/script;sh /home/crawl/exec_aqi.sh &  > /dev/null 2>&
如果直接修改 /etc/crontab 文件
SHELL=/bin/bash
PATH=/sbin:/bin:/usr/sbin:/usr/bin
MAILTO=root
00 10 * * * crawl sh /home/crawl/exec_aqi.sh &
https://zcdll.github.io/2018/01/30/own-crontab/
```
### 终端技巧大集合
```javascript
# ‘{}’ 可用于匹配多个模式的文件名 
ls {*.sh,*.py}   #列出所有.sh和.py文件
筛选匹配前后返回的行（例如 “bbo”）

# return also 3 lines after match
grep -A 3 'bbo'

# return also 3 lines before match
grep -B 3 'bbo'

# return also 3 lines before and after match
grep -C 3 'bbo'
删除前 100 行（删除第 1-100 行）

sed 1,100d filename
删除带字符串的行 (例如： bbo)

sed "/bbo/d" filename
- case insensitive:
sed "/bbo/Id" filename
删除空行

sed '/^\s*$/d'

# 或

sed '/^$/d'
查找且删除

find . -name "*.html"|xargs rm

# when using a backtick
rm `find . -name "*.html"`
https://learnku.com/laravel/t/35317#replies
```
### 网络知识之 IP 与子网掩码
```javascript
IP 地址是一种在 Internet 上的给主机编址的方式，也称为网际协议地址。IP 地址是 IP 协议提供的一种统一的地址格式，它为互联网上的每一个网络和每一台主机分配一个逻辑地址，以此来屏蔽物理地址的差异。常见的 IP 地址，分为 IPv4 与 IPv6 两大类。主要介绍的是 IPv4 这一类。 IP 地址是一个 32 位的二进制数，但为了方便记忆，通常被分割为 4 个 "8 位二进制数"，并且用 "点分十进制" 表示为 a.b.c.d 的形式，其中 a,b,c,d 都是 0~255 之间的十进制整数。

IP 地址分为五类，各类可容纳的地址数目不同：

A 类保留给政府机构（0.0.0.0 到 127.255.255.255）

B 类分配给中等规模的公司（128.0.0.0 到 191.255.255.255）

C 类分配给任何需要的人（192.0.0.0 到 223.255.255.255）

D 类用于组播（224.0.0.0---239.255.255.255）

E 类用于实验（240.0.0.0---247.255.255.255）

A、B、C 三类中 IP 地址 = 网络地址 + 主机地址，而 D、E 两类不区分网络地址和主机地址

特殊说明：

（1）A 类中的 10.X.X.X 是私有地址；127.X.X.X 是保留地址

（2）B 类中的 172.16.0.0~172.31.255.255 是私有地址

（3）C 类中的 192.168.X.X 是私有地址
网络地址可以简单理解我们平时常说的网段

主机地址则是在这个网段中不同设备的地址
子网掩码只有一个作用，就是将一个 IP 地址划分成网络地址和主机地址两部分。

（常见的掩码是由一连串 1 + 一连串 0 构成的，不过看网上资料也说 1 和 0 交替也是可以的）

默认分配的子网掩码每段只有 255 或 0

A 类的默认子网掩码　255.0.0.0
B 类的默认子网掩码　255.255.0.0　　
C 类的默认子网掩码　255.255.255.0
子网掩码与 IP 地址一样是 32 位地址，然后将 IP 地址与子网掩码进行与运算即可得到网络地址。

例：

IP地址为192.168.10.2，子网掩码为255.255.255.240。
先将十进制转换成二进制：
IP地址：  11000000 10101000 00001010 00000010
子网掩码： 11111111 11111111 11111111 11110000
进行与运算：－－－－－－－－－－－－－－－－－－－－－－－－－－
          11000000 10101000 00001010 00000000
则可得其网络标识为192.168.10.0，主机标识为2。
3. 掩码的不同表示形式

已经说过了子网掩码也是 32 位的地址，那么开头的 25 怎么转化呢？

25 的意思是网络号为 25，就代表连续的 25 个 1，然后剩下的用 0 补齐

即 11111111 11111111 11111111 10000000

4. 包含的其他信息

还是以这个信息为例：XX.XX.XX.128/25，我们还可以拿到什么信息呢？

（1）主机号：主机号 + 网络号 = 32，32-25=7

（2）网络地址：当 7 位主机号全为 0，也就是 XX.XX.XX.128

（3）广播地址：当 7 位主机号全为 1，也就是 XX.XX.XX.255

（4）可用地址数量：7 位主机号有 2^7 种结果，但是要去掉网络地址和广播地址，即：2^7-2=126 (这个也就是运维所说的一百多个 ip)https://learnku.com/articles/35666 
```
### ssh免密登录漏洞
```javascript
[root@localhost ~]# ll .ssh/
total 42944
-rw-r--r-- 1 root root 43918390 Nov  6  2017 authorized_keys
-rw-r--r-- 1 root root     3415 Apr 26  2019 known_hosts
[root@localhost ~]# cat .ssh/known_hosts
git.coding.net,221.193.246.6 ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQDHOWdwLpkos2CLli6DFvQ36yQE6Pe/PtFp3XwyirfZCIoGWnedaWI8zkJWVCs0wgOB9/urFepTDfV2wN49KGy1sl2/CCDEH2K/zeoEAZlTcBrhU17bwg1yMHCyJ7IM+zdLzItDEKYjgoWqVdUGK1dXQQlwt7GP4W7HqffelQQoVxOMoZ5N50MzD+nvV4y8iq0KwDQNy62iU4hui9ajCSVUDLu/06ucd5IojSI9keRIYAXvQf52TJ5EbvoBggp9RhjuWNEG8IhnPP6rzPS11Ocmwg/Hs
打开 vi authorized_keys 并没有任何东西。然后我顺带把其它 /root/.ssh/ 下的四个文件都翻了一遍。
才发现 known_hosts 文件中多了两个 IP 地址为新加坡的 ssh key  https://learnku.com/articles/35888
```
### crontab 指定用户
```javascript
直接在 /etc/crontab 中编辑定时任务即可，加上用户名
SHELL=/bin/sh
PATH=/usr/local/sbin:/usr/local/bin:/sbin:/bin:/usr/sbin:/usr/bin

# Example of job definition:
# .---------------- minute (0 - 59)
# |  .------------- hour (0 - 23)
# |  |  .---------- day of month (1 - 31)
# |  |  |  .------- month (1 - 12) OR jan,feb,mar,apr ...
# |  |  |  |  .---- day of week (0 - 6) (Sunday=0 or 7) OR sun,mon,tue,wed,thu,fri,sat
# |  |  |  |  |
# *  *  *  *  * user-name command to be executed
17 *    * * *   root    cd / && run-parts --report /etc/cron.hourly
25 6    * * *   root    test -x /usr/sbin/anacron || ( cd / && run-parts --report /etc/cron.daily )
47 6    * * 7   root    test -x /usr/sbin/anacron || ( cd / && run-parts --report /etc/cron.weekly )
52 6    1 * *   root    test -x /usr/sbin/anacron || ( cd / && run-parts --report /etc/cron.monthly )
#

# cron
* * * * *  www-data flock /tmp/flock1.lock -c 'timeout 200 /usr/local/bin/php /var/www/html/laravel/artisan command >> /home/log/laravel.log 2>&1'
flock 用来防止重复执行，起到原子锁作用
                                                                                                                                                  timeout 表示这个脚本执行过长，咱就干死它，可以有效避免各种循环或长时间占用问题
https://learnku.com/articles/35948

* * * * * flock -xn /tmp/test.lock -c "timeout 200 php /home/app/email.php >> /home/log/test.log 2>&1" 
想 10s 执行一次怎么办？

* * * * * php /home/app/email.php >> /home/log/test.log 2>&1
* * * * * ( sleep 10 ; php /home/app/email.php >> /home/log/test.log 2>&1 )
* * * * * ( sleep 20 ; php /home/app/email.php >> /home/log/test.log 2>&1 )
* * * * * ( sleep 30 ; php /home/app/email.php >> /home/log/test.log 2>&1 )
* * * * * ( sleep 40 ; php /home/app/email.php >> /home/log/test.log 2>&1 )
* * * * * ( sleep 50 ; php /home/app/email.php >> /home/log/test.log 2>&1 )
```
### >  >>
```javascript
> 表示覆盖追加
>> 表示尾部追加
这两个管道操作符，在执行期间发生错误时，是不会将错误输出写入后面的「文件」中的。
在 Linux 系统中 0、1、2 分别表示不同的设备类型，其中

0 标准输入设备，指键盘
1 标准正确输出设备
2 标准错误输出设备
php artisan command >> /home/log/laravel.log 2>&1'
上面命令的意思是将 php artisan command 的 标准正确输出 重定向到 laravel.log 文件。
而后面的 2>&1 是表示将标注错误输出重定向到标准正确输出。

从而达到错误输出和正确输出都记录在 laravel.log 文件中。

```
### 内网穿透
```javascript
https://serveo.net/
λ ssh -R 80:localhost:3000 serveo.net
Forwarding HTTP traffic from https://habeo.serveo.net
Press g to start a GUI session and ctrl-c to quit.

```
### ab 压力测试
```javascript
ab -n 2000 -c 1000 http://www.xxx.com/index.php
需要调整内核参数以支持端口重用
假如我现在使用的是 Linux 服务器，找到如下文件
sudo vim /etc/sysctl.conf
添加如下内容

net.ipv4.tcp_syncookies = 1
net.ipv4.tcp_tw_reuse = 1
net.ipv4.tcp_tw_recycle = 1
net.ipv4.tcp_fin_timeout = 30
kernel.printk = 7 4 1 7
运行 sudo sysctl –p 生效
https://learnku.com/articles/4765/simple-primary-stress-test
```
### https 证书注册工具
```
apt-get install certbot python-certbot-nginx
certbot --nginx
certbot renew --dry-run

https://certbot.eff.org/
```
### linux卡顿怎么排查
```javascript
ps -ef | grep php | awk '{print $2}' | xargs kill -9
查看内存使用状况：free -g
查看磁盘使用状况：df -h
查看磁盘I/O使用：iostat -dx
查看CPU使用：top

awk '条件类型 1{动作1} 条件类型2{动作2} ...' filename
awk后面接两个引号并加上大括号来设置想要对数据进行的处理动作。https://tsmliyun.github.io/linux/%E4%B8%80%E6%AC%A1%E5%AE%9A%E6%97%B6%E4%BB%BB%E5%8A%A1%E9%85%8D%E7%BD%AE%E9%94%99%E8%AF%AF%E5%BC%95%E5%8F%91%E7%9A%84%E6%80%9D%E8%80%83/
```


### docker 
```javascript

curl -L "https://github.com/docker/compose/releases/download/1.24.1/docker-compose-$(uname -s)-$(uname -m)" -o /usr/local/bin/docker-compose
chmod +x /usr/local/bin/docker-compose
[root@VM_0_11_centos html]# docker-compose version
docker-compose version 1.24.1, build 4667896b
docker-py version: 3.7.3
CPython version: 3.6.8
OpenSSL version: OpenSSL 1.1.0j  20 Nov 2018
 docker pull gogs/gogs
 [root@VM_0_11_centos html]# docker start gogs
 gogs
 [root@VM_0_11_centos html]# docker ps
 CONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS
   PORTS                                            NAMES
 1bd82406bba2        gogs/gogs           "/app/gogs/docker/st…"   7 hours ago         Up 7 hours
   0.0.0.0:10022->22/tcp, 0.0.0.0:10080->3000/tcp   gogs
   
   https://learnku.com/articles/34941
   
```
### cURL error 28: Resolving timed out after 5515 milliseconds
```javascript
$ cat /etc/resolv.conf
不要手动修改 /etc/resolv.conf，因为此文件动态生成的，先看下文件：

$ cat /etc/network/interfaces
最后一行的 dns-nameservers 是我们的目标，开始修改：

$ vi /etc/network/interfaces
比较知名的公共 DNS 可以请问这里查看 https://www.ip.cn/dns.html ，这里选择 114 和 阿里的 DNS:

auto lo
iface lo inet loopback
auto eth0
iface eth0 inet static
address 10.x.23.xxx
netmask 255.255.0.0
gateway 10.x.0.x
mtu 1454
dns-nameservers 114.114.114.114 114.114.115.115 223.5.5.5
最后面 dns-nameservers 是 DNS ，修改最后一行即可，修改完成后：

$ ifdown eth0 && sudo ifup eth0
重启成功后，确认是否应用上：

$ cat /etc/resolv.conf
可以看到输出：

# Dynamic resolv.conf(5) file for glibc resolver(3) generated by resolvconf(8)
#     DO NOT EDIT THIS FILE BY HAND -- YOUR CHANGES WILL BE OVERWRITTEN
nameserver 114.114.114.114
nameserver 114.114.115.115
nameserver 223.5.5.5
https://learnku.com/ubuntu/t/32705 
```
### 内存消耗最大的进程
```javascript
[root@VM_0_11_centos html]# ps aux --sort -rss | head
USER       PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND
root      3367  0.0  3.9 523176 74068 ?        Ssl  Nov14   0:53 /usr/bin/dockerd -H fd:// --containerd
=/run/containerd/containerd.sock
ps -eo pid,ppid,%mem,%cpu,cmd --sort=-%mem | head
如果你只想查看命令名称而不是命令的绝对路径，请使用下面的 ps 命令格式。

# ps -eo pid,ppid,%mem,%cpu,comm --sort=-%mem | head
# top -c -b -o +%MEM | head -n 20 | tail -15
如果你只想查看命令名称而不是命令的绝对路径，请使用下面的 top 命令格式。

# top -b -o +%MEM | head -n 20 | tail -15
https://cn.v2ex.com/t/619291#
```
### Nginx 负载均衡
```javascript
语法: upstream name { ... } 
默认值: —
上下文: http

upstream 指令当中包含server指令
语法: server address [parameters]; 
上下文: upstream

例子:
upstream backend {
    server backend1.example.com:8081 weight=4 max_fails=2 fail_timeout=30s; 
    server backend2.example.com:8080 weight=1;
}
server { 
    location / {
        proxy_pass http://backend; 
    }
}

参数说明:
weight=number 设定服务器的权重，默认是1，权重越大被访问机会越大，可以根据机器的配置情况来配置。

max_fails=number 设定Nginx与服务器通信的尝试失败的次数。在fail_timeout参数定义的时间段内，如果失败的次数达到此值，Nginx就认为服务器不 可用。在下一个fail_timeout时间段，服务器不会再被尝试。 失败的尝试次数默认是1。

默认配置时，http_404状态不被认为是失败的尝试。 可以通过指令proxy_next_upstream 和memcached_next_upstream来配置什么是失败的尝试。

fail_timeout=time
统计失败尝试次数的时间段。在这段时间中，服务器失败次数达到指定的尝试次数，服务器就被认为不可用。默认情况下，该超时时间是10秒。 

backup
标记为备用服务器。当主服务器不可用以后，请求会被传给这些服务器，配置这个指令可以实现故障转移。

down 标记服务器永久不可用，可以跟ip_hash指令一起使用。
https://learnku.com/articles/36737
```
### Nginx 配置常用参数
```javascript
# 配置用户或者组，默认为nobody nobody。
#user www www;  

 #Nginx开启的worker进程数，建议为CPU的核数
#worker_processes 2; 

#指定nginx进程运行文件存放地址
#pid /nginx/pid/nginx.pid;

#指定日志路径，级别。这个设置可以放入全局块、http块、server块，级别以此为：debug|info|notice|warn|error|crit|alert|emerg
error_log log/error.log debug; 

#可以在任意地方使用include指令实现配置文件的包含，类似于apache中的include方法，可减少主配置文件长度。
include vhosts/*.conf;
事件模块

events {
    #设置网路连接序列化，防止惊群现象发生，默认为on
    accept_mutex on; 

    #默认: 500ms 如果一个进程没有互斥锁，它将延迟至少多长时间。默认情况下，延迟是500ms 。
    accept_mutex_delay 100ms; 

    #设置一个进程是否同时接受多个网络连接，默认为off
    multi_accept on;

    #事件驱动模型，select|poll|kqueue|epoll|resig|/dev/poll|eventport，不建议设置，nginx会自行选择
    #use epoll;

    #最大连接数，默认为512
    worker_connections  1024;
}
http 部分

http {
    #文件扩展名与文件类型映射表
    include       mime.types;

    # 默认文件类型，默认为text/plain
    default_type  application/octet-stream; 

    #取消服务日志 
    #access_log off; 

    #允许sendfile方式传输文件，默认为off，可以在http块，server块，location块。
    sendfile on;   

    #每个进程每次调用传输数量不能大于设定的值，默认为0，即不设上限。
    sendfile_max_chunk 100k;  

    #连接超时时间，默认为75s，可以在http，server，location块。
    keepalive_timeout 65;  

    #开启gzip资源压缩
    gzip  on; 

    # 负载均衡，详细可看了一篇文章：https://learnku.com/articles/36737
    upstream blog {   
        server 192.167.20.19:8081;
        server 192.168.10.121:8080 weight=5;
    }

    #设定请求缓冲
    client_header_buffer_size    128k;
    large_client_header_buffers  4 128k;

    #上传文件的大小限制  默认1m
    client_max_body_size 8m;

    server {
        #单连接请求上限次数。
        keepalive_requests 120;

        #监听端口
        listen       80;   

        #监听地址
        server_name  blog.13sai.com;  

        #设定日志格式
        log_format  main  '$remote_addr - $remote_user [$time_local] "$request" '
                      '$status $body_bytes_sent "$http_referer" '
                      '"$http_user_agent" "$http_x_forwarded_for"';

        access_log  /data/logs/access.log  main;

        # 根目录
        root /www/web/public; 

        # 定义错误提示页面
        error_page   500 502 503 504 /50x.html;

        location /static/ {
            #root与alias主要区别在于nginx如何解释location后面的uri，这会使两者分别以不同的方式将请求映射到服务器文件上。
            #root的处理结果是：root路径＋location路径
            #alias的处理结果是：使用alias路径替换location路径
            alias /www/static/;

            #过期30天，静态文件不怎么更新，过期可以设大一点,如果频繁更新，则可以设置得小一点。
            expires 30d;
        }

        # 处理php请求到fpm端口
        location ~ \.php$ {
            fastcgi_pass   127.0.0.1:9000;
            fastcgi_index  index.php;
            fastcgi_param  SCRIPT_FILENAME  $document_root$fastcgi_script_name;
            include        fastcgi_params;
        }

        location / {
            proxy_set_header Host $host;
            proxy_set_header  X-Real-IP  $remote_addr;
            proxy_pass  http://blog;  #请求转向blog 定义的服务器列表 
        }

        #禁止访问文件
        location ~ /.git {
            deny all;
            allow 127.0.0.1; #允许的ip 
        }
    }
} https://learnku.com/articles/36768

```
### 反向代理后如何获取真实客户端 IP
```javascript
 location /api { 
            rewrite  ^/api/(.*)$ /api/$1 break;
            proxy_pass   https://***.*********.com;
    }
    proxy_set_header X-Forwarded-For $remote_addr;
    proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
    如果有报错
    Starting nginx: nginx: [warn] could not build optimal proxy_headers_hash, you should increase either proxy_headers_hash_max_size: 512 or proxy_headers_hash_bucket_size: 64; ignoring proxy_headers_hash_bucket_size
    
        nginx.conf 下的http 模块下设置
        proxy_headers_hash_max_size 51200;
        proxy_headers_hash_bucket_size 6400;
    
    3 代码里面获取
       $ip = $_SERVER['HTTP_X_FORWARDED_FOR'];
    https://learnku.com/articles/36832

```
### docker 入门
```javascript
Docker 是一个开源的应用容器引擎，让开发者可以打包他们的应用以及依赖包到一个可移植的镜像中，然后发布到任何流行的 Linux 或 Windows 机器上，也可以实现虚拟化。容器是完全使用沙箱机制，相互之间不会有任何接口。
docker images -- 常看本地镜像
docker ps -- 查看容器，默认只查看已启动的，加入 "-a" 参数可以查看所有
docker start|stop|rm|rmi -- 容器的相关操作，分别对应： 开启 | 停止 | 删除容器 | 删除镜像
docker pull ubuntu

docker run -itd --name test-ubuntu ubuntu
docker exec -it test-ubuntu /bin/bash
docker pull php:7.3.5-fpm
docker run -itd -p 9001:9000 -v /Users/admin/Site/php7.3.5:/data --name php-test php:7.3.5-fpm
docker exec -it php-test /bin/bash
vi /etc/nginx/config.d/php.conf
server {
    # 监听端口
    listen       8002;

    # 域名设定
    server_name  122.51.155.172;

    root /usr/share/nginx/html/php/; # 该项要修改为你准备存放相关网页的路径，如果存在fast-cgi的root字段，这里貌似就没效果了

    location / {

    index index.php index.html;

    # 打开目录浏览功能，可以列出整个目录

    autoindex on;

    }

    #proxy the php scripts to php-fpm

    location ~ \.php$ {
    # fastcgi配置

    # 指定是否传递4xx和5xx错误信息到客户端

    fastcgi_intercept_errors on;

    # 指定FastCGI服务器监听端口与地址，可以是本机或者其它,这里是重点，需要指定php-fpm容器的端口和根目录
    fastcgi_pass   127.0.0.1:9001;
    root /data;
    fastcgi_index index.php;
    include  fastcgi_params;
    fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name;
    }

}
sysctemclt restart nginx 
vi /usr/share/nginx/html/php/inde.php 
访问http://122.51.155.172:8002/
Dockerfile 是一个包含用于组合映像的命令的文本文档。可以使用在命令行中调用任何命令。 Docker 通过读取 Dockerfile 中的指令自动生成映像。
FROM php:7.3.5-fpm
MAINTAINER liyan

#安装环境系统命令
RUN apt-get update && apt-get install -y \
vim \
libssl-dev

#安装PHP扩展
RUN pecl install igbinary \
redis-4.0.2 \
swoole

#配置php.ini
RUN cp /usr/local/etc/php/php.ini-production /usr/local/etc/php/php.ini && \
ln -s /usr/local/etc/php/php.ini /etc/php.ini && \
echo "extension=igbinary.so\nextension=redis.so\nextension=swoole.so" >> /etc/php.ini

EXPOSE 9300
VOLUME ["/data"]
WORKDIR /data
https://learnku.com/articles/36739
```
### 忽略文件
```javascript
已经推送 push 过的文件，想在以后的提交时忽略此文件，即使本地已经修改过，而且不删除 Git 远程库中相应文件，后面的 Xml/config.xml 是要忽略的文件的路径，执行命令：

git update-index --assume-unchanged Xml/config.xml  
恢复忽略的文件，执行命令：

git update-index --no--assume-unchanged Xml/config.xml  
如果要忽略一个目录，打开 git bash，定位到目标目录下，后面的 Xml/test/ 是要忽略的目录的路径，执行命令：

git update-index --assume-unchanged $(git ls-files Xml/test/ | tr '\n' ' ')
清除指定目录下没有被 push 过的文件和文件夹，执行命令：

git clean -df supplier/web    https://learnku.com/articles/37298
```
### crontab %截断
```javascript
0 0 * * * cd /home/vg/odp/log && mv *`date -d "-10 day" "+%Y%m%d"`* archives
crontab的执行情况，linux都会给对应的用户发邮件，因此可以通过邮件来定位问题。上面的任务在vg用户下，查看对应的邮件 /var/spool/mail/vg
Subject那一行：
Subject: Cron cd /home/vg/odp/log && mv *`date -d "-10 day" "+
显示的命令不全，到加号就结束了，%和后面的部分丢失了，结合报错基本可以定位原因，%是crontab里的特殊符号，表示新的一行开始，所以前面的命令就被截断了。
解决方式

如果crontab执行的命令中包含%需要用\转义，上面的例字改成这样就可以成功执行：
0 0 * * * cd /home/vg/odp/log && mv *`date -d "-10 day" "+\%Y\%m\%d"`* archives
https://www.daemoncoder.com/a/%E8%AE%B0%E4%B8%80%E6%AC%A1crontab%E4%B8%ADdate%E5%91%BD%E4%BB%A4%E9%94%99%E7%94%A8%E5%AF%BC%E8%87%B4%E7%9A%84%E9%97%AE%E9%A2%98/4d54453d

```
### 查出访问量TOP10的IP
```javascript
日志文件access.log格式如下：

127.0.0.1 - - [18/Nov/2018:17:26:54 +0800] "GET / HTTP/1.0" 200 3283 "-" "" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/70.0.3538.102 Safari/537.36" 0.012 127.0.0.1 127.0.0.1:9000 daemoncoder.com "-"
Linux命令：

awk -F " " '{count[$1]++} END {for (i in count) {printf("%s\t%d\n", i, count[i]);}}' access.log | sort -nrk 2 | head
通过awk对日志中的每一行ip进行计数统计，并按ip count格式输出。

通过sort命令按照第二列降序排序：-t 指定分割符是空格; -n指定按数字大小排序; -r 指定降序输出; -k 指定按分隔后的第二列排序

通过head命令取出前十条。https://www.daemoncoder.com/a/%E4%B8%80%E8%A1%8CLinux%E5%91%BD%E4%BB%A4%E6%9F%A5%E5%87%BA%E8%AE%BF%E9%97%AE%E9%87%8FTOP10%E7%9A%84IP/4d773d3d

```
### phpmyadmin 管理多台 MySQL
```javascript
复制 phpMyAdmin 根目录下的 config.sample.inc.php 文件，重命名为 config.inc.php；
在文件中定义你的多台服务器配置信息：
$hosts = [
    1 => ['host' => 'localhost', 'user' => 'root', 'password' => 'root'],
    2 => ['host' => '192.168.10.10', 'user' => 'homestead', 'password' => 'secret']
];
在加入以下代码片段，通过 for 循环来读取多台 MySQL 服务器配置信息
for($i = 1; $i <= count($hosts); $i++){
    /* Authentication type */
    $cfg['Servers'][$i]['auth_type'] = 'cookie';
    /* Server parameters */
    $cfg['Servers'][$i]['host'] = $hosts[$i]['host'];    //修改host
    $cfg['Servers'][$i]['connect_type'] = 'tcp';
    $cfg['Servers'][$i]['compress'] = false;
    /* Select mysqli if your server has it */
    $cfg['Servers'][$i]['extension'] = 'mysql';
    $cfg['Servers'][$i]['AllowNoPassword'] = true;
    $cfg['Servers'][$i]['user'] = $hosts[$i]['user'];    //修改用户名
    $cfg['Servers'][$i]['password'] = $hosts[$i]['password'];    //密码
}
https://learnku.com/articles/31740
```
### pull request流程
```javascript
在 GitHub 上把本项目 fork 到自己的仓库，如 <your-username>/php-developer-prepares，然后 clone 到本地，并设置用户信息。
$ git clone git@github.com:<your-username>/php-developer-prepares.git
$ cd php-developer-prepares
$ git config user.name "yourname"
$ git config user.email "your email"
修改代码后提交，并推送到自己的仓库。
$ #do some change on the content
$ git commit -am "Fix issue #1: change helo to hello"
$ git push
在 GitHub 网站上提交 pull request。
定期使用项目仓库内容更新自己仓库内容。
$ git remote add upstream https://github.com/zacao/php-developer-prepares
$ git fetch upstream
$ git checkout master
$ git rebase upstream/master
$ git push -f origin master

```
###  SSH 也通过 SS 代理
```javascript
 配置您的 ~/.ssh/config 文件，增加以下的内容即可：

Host github.com
   HostName github.com
   User git
   ProxyCommand nc -v -x 127.0.0.1:1086 %h %p
https://learnku.com/articles/37108
```
### Github 关键字进行搜索
```javascript
in:name Laravel
in:readme Laravel
in:decription Laravel
in:description Laravel stars:>1000 forks:>1000
in:descrption Laravel stars:1000..2000
in:description 验证码 language:php
in:description 验证码 language:php pushed:>2019-05-01 # 过滤大于 2019-05-01之后提交的
in:description 验证码 language:php created:>2019-05-01 # 过滤大于 2019-05-01创建的
user:overtrue
user:laravel
https://learnku.com/articles/38106 https://github.com/search/advanced
followers:>1000 language:PHP location:China
```
### Bash 单命令行解释
```javascript
清空文件  > file
 echo "some string" > file
 echo "foo bar baz" >> file
 line=$(head -1 file)
 line=`head -1 file` 
 一行行地读取文件 
 
 $ while read -r line; do
     # do something with $line
 done < file
 
 $ str="hello world"
 $ echo ${str:6}//world
 echo ${str:7:2}
 echo ${#str}//12
 $ if [[ $str =~ [0-9]+.[0-9]+ ]]; then
     # 执行一些操作
 fi
 $ if [[ $file = *.zip ]]; then
     # 执行一些操作
 fi
 $ if [[ $answer = [Yy]* ]]; then
     # 执行一些操作
 fi
 $ str=baz-foo-bar-foo-foo
 $ echo ${str/foo/bar}
 baz-bar-bar-foo-foo
 $ echo "$x$y"//合并
 $ echo foo{,,,,,,,,,,}//重复生成
 echo {a,b,c}{1,2,3}
 a1 a2 a3 b1 b2 b3 c1 c2 c3
printf "%02d " {0..9}//00 01 02 03 04 05 06 07 08 09
echo {1..100}
$ echo {a..z}//a b c d e f g h i j k l m n o p q r s t u v w x y z
echo $(printf "%c" {a..z})
abcdefghijklmnopqrstuvwxyz

https://learnku.com/articles/38528
 https://learnku.com/articles/38449
```
### 列出目录下所有被 git 忽略的文件
find . -type f  | git check-ignore --stdin

### SSH 闲置时间过长而断开
```javascript
//  修改/etc/ssh/sshd_config配置文件，找到ClientAliveCountMax（单位为分钟）修改你想要的值，
//   执行
$ service sshd reload 

//  找到所在用户的.ssh目录,如root用户该目录在：
$  /root/.ssh/
//  在该目录创建config文件
$ vi /root/.ssh/config
//  加入下面一句：
ServerAliveInterval 60
//  保存退出，重新开启root用户的shell，则再ssh远程服务器的时候，
不会因为长时间操作断开。应该是加入这句之后，ssh客户端会每隔一
段时间自动与ssh服务器通信一次，所以长时间操作不会断开。
https://learnku.com/articles/38759
// 修改/etc/profile配置文件
$ vi /etc/profile
增加：TMOUT=1800
这样30分钟没操作就自动LOGOUT
```
### 安装 swoole laravelS
```javascript

pecl install swoole 
$ pecl channel-update pecl.php.net
$ php -r "print_r(openssl_get_cert_locations());"
[default_cert_file] => /usr/lib/ssl/cert.pem
[default_cert_file_env] => SSL_CERT_FILE
[default_cert_dir] => /usr/lib/ssl/certs
[default_cert_dir_env] => SSL_CERT_DIR
[default_private_dir] => /usr/lib/ssl/private
[default_default_cert_area] => /usr/lib/ssl
[ini_cafile] =>
[ini_capath] =>
安装证书
$ wget -c https://curl.haxx.se/ca/cacert.pem  /usr/local/openssl/cert.pem --no-check-certificate
开启 swoole 扩展
$ echo 'extension=swoole.so' >> /etc/php/7.3/mods-available/swoole.ini
$  ln -s /etc/php/7.3/mods-available/swoole.ini /etc/php/7.3/cli/conf.d/20-swoole.ini

https://learnku.com/articles/38355 
```
### error src refspec matches more than one
```javascript
git push origin test
error: src refspec test matches more than one.
error: failed to push some refs to
git tag |grep test
因为有一个与当前提交分支同名的标签
git tag -d test
git push origin test
```
### ssh 连接 实现免密码登陆
```javascript
1.主配置文件于/etc/ssh/sshd_config
2.Port 22 端口声明指定sshd服务器将侦听连接的端口 
如需更改端口 直接添加后  测试完成 再删除 22
3.PermitRootLogin 选择是否允许root登录
4.LoginGraceTime 指定在未成功登录的情况下保持连接活动的秒数
[root@7S ssh]# sudo service ssh restart  重启服务
[root@7S ssh]# sudo systemctl restart ssh

[root@7S ssh]# systemctl stop firewalld.service //关闭防火墙
    [root@7S ssh]# systemctl is-enabled firewalld.service //查看防火墙状态
    enabled
    [root@7S ssh]# firewall-cmd --zone=public --add-port=1212/tcp --permanent 添加 放行端口 1212
    FirewallD is not running // 防火墙关闭
    [root@7S ssh]# systemctl restart firewalld.service //启动
    [root@7S ssh]# firewall-cmd --zone=public --add-port=1212/tcp --permanent //继续添加
    success 
     [root@7S ssh]# firewall-cmd --zone=public --list-ports //查看所有端口
[root@7S ssh]# ssh-keygen -t rsa //创建
按 Enter 键接受默认值  (Mac)密钥在〜/.ssh/id_rsa.pub和〜/.ssh / id_rsa中 (window 系统不一样 Admin文件名不一样) /C/users/Admin/.ssh/id_rsa
ssh-copy-id root@192.168.100.00 // 将公钥复制到远程服务器 输入密码 下次不需要使用密码 即可登录

更改 端口 登录
$ ssh -p 1212 root@192.168.100.00

安全考虑 禁用密码验证

[root@7S ssh]# /etc/ssh/sshd_config
// PasswordAuthentication no //去掉注释 改为 no
// PubkeyAuthentication yes   // 默认不修改
// ChallengeResponseAuthentication no // 默认不修改
sudo systemctl restart ssh // 重启服务 如有错误 关闭 SELinux 或者 向 SELinux 中添加修改的 SSH 端口 (如下)

ssh-copy-id -i ~/.ssh/id_rsa.pub root@192.168.100.000 // 将本机的 id_rsa.pub 公钥文件内容复制到远程目标机的.ssh/authorized_keys 文件中

本地复制: scp .ssh/id_rsa.pub user@192.168.1.100:/home/root/

服务器操作:

[root@7S ssh]# mkdir -p /home/root/.ssh/
[root@7S ssh]# mv /home/root/id_rsa.pub /home/root/.ssh/authorized_keys  //authorized_keys 必须如此命名
https://learnku.com/articles/38761


```
### CentOS 部署 Laravel 应用
```javascript
$ yum install nginx 
$ systemctl nginx start   # 启动 Nginx 
$ systemctl nginx stop    # 停止 Nginx 
$ systemctl nginx restart # 重启 Nginx
$ systemctl enable nginx.service # 设置开机自启动
$ systemctl disable nginx # 禁用 Nginx 开机启动
$ systemctl list-dependencies | grep nginx # 检查开机自启动是否设置成功
浏览器访问不成功 解决办法
方法一: systemctl stop firewalld.service  # 关闭防火墙
方法二: firewall-cmd --zone=public --add-port=80/tcp --permanent # 添加80端口
firewall-cmd --reload # 重启防火墙
firewall-cmd --list-ports # 查看是否添加成功
1212/tcp 80/tcp # 显示 即成功 1212 设置的其他端口
浏览器访问
Welcome to nginx! # 成功显示
安装 PHP

$ yum install -y php72w php72w-cli php72w-fpm # PHP 自身 / cli PHP 的命令行接口 / 用于管理 PHP 进程，并提供 FastCGI 接口与 Nginx 交互
$ yum install -y php72w-mbstring php72w-xml php72w-bcmath # 安装扩展 
$ php -m # 查看扩展
$ php -v # 查看 PHP 版本
$ systemctl restart php-fpm # 重启 PHP-FPM 
$ systemctl start php-fpm # 启动 PHP-FPM 
$ systemctl stop php-fpm # 停止 PHP-FPM
$ systemctl enable php-fpm # 启用 PHP-FPM 开机启动 
$ systemctl disable php-fpm # 禁用 PHP-FPM 开机启动  
$ ps aux | grep php # 确认 PHP-FPM 正常运行 

$ yum install -y git
$ git --version # 查看 git 版本
# 生成 SSH 秘钥
$ ls -al ~/.ssh # 查看是否 存在 `id_rsa` 与文件 `id_rsa.pub`
$ ssh-keygen -t rsa -C "your_email@example.com" # 一路回车【密码为空】
$ ls -al ~/.ssh # 再次查看是否生成成功
$ cat ~/.ssh/id_rsa.pub # 查看公钥内容
Composer
############################################
$ php -r "copy('https://getcomposer.org/installer', 'composer-setup.php');"  # 或者使用 `$ wget -O composer-setup.php https://getcomposer.org/installer` $ php -r "if (hash_file('sha384', 'composer-setup.php') === 'a5c698ffe4b8e849a443b120cd5ba38043260d5c4023dbf93e1558871f1f07f58274fc6f4c93bcfd858c6bd0775cd8d1') { echo 'Installer verified'; } else { echo 'Installer corrupt'; unlink('composer-setup.php'); } echo PHP_EOL;" 
$ php composer-setup.php --filename=composer --install-dir=/usr/local/bin --version=1.9.0 
$ php -r "unlink('composer-setup.php');"  # 检查安装情况 
$ composer --version # 淘宝全量镜像【https://learnku.com/composer/wikis/30594】 
$ composer config -g repo.packagist composer https://mirrors.aliyun.com/composer/  

$ rpm -ivh https://dev.mysql.com/get/mysql80-community-release-el7-3.noarch.rpm # 安装 mysql 官方 yum 源
$ yum list |  grep mysql # 查看 MySQL yum 源 发现只有 mysql80 的包，这是因为没有开启 mysql57 的包 
$ yum-config-manager --disable mysql80-community # 关闭 80 包，开启 57 包
$ yum-config-manager --enable mysql57-community # 遇到问题 yum-config-manager: command not found  解决 安装 yum -y install yum-utils
$ yum list |  grep mysql # 发现有了 mysql57 的包
$ yum install -y mysql-community-server # 安装 mysql
$ yum install -y mysql-community-client # 根据需要安装（可不装）
$ systemctl start mysqld # 启动 mysql
$ systemctl stop mysqld # 停止 mysql
$ service mysqld status # 或 ps -ef | grep mysql //检查mysql正常启动
$ systemctl enable mysqld.service #设置mysqld服务开机自启动 　
$ systemctl list-dependencies | grep mysqld #检查mysqld开机自启动是否设置成功
$ grep 'temporary password' /var/log/mysqld.log # 查看超级账户 root 临时密码 mysql5.7 增强了安全机制, 系统会自动生成一个随机的密码
$ mysql  -uroot  -p
mysql> ALTER USER "root"@"localhost" IDENTIFIED BY '你的新密码'; # 修改超级账户 root 密码
mysql> flush privileges;
mysql> exit;
$ systemctl restart mysqld.service
https://learnku.com/articles/35573#reply123613

```
### Docker Contos 搭建 PHP 环境
```javascript
docker pull nginx // 拉取官方镜像
docker images // 查看
docker run -p 80:80 -d --name mynginx -v /docker/www:/usr/share/nginx/www nginx // 开启 nginx 应用容器
-p 80:80：将容器的80端口映射到主机的80端口 -d 后台运行(守护进程) --name mynginx：将容器命名为mynginx -v 将主机中当前目录下的www挂载到容器的www目录

docker ps -a // 查看容器启动情况
docker pull php:7.2-fpm // 拉取官方 PHP 镜像
docker images // 查看
docker run -p 9000:9000 -d --name myphp-fpm -v /docker/www:/usr/share/nginx/www php:7.1-fpm // 开启 php-frm 应用容器
docker ps -a // 查看容器启动情况
docker inspect myphp-fpm | grep "IPAddress" // 查看 ip 信息
"SecondaryIPAddresses": null,
"IPAddress": "172.17.0.3",
"IPAddress": "172.17.0.3",
[root@localhost ~]# docker exec -it mynginx bash // 进入容器
vi /etc/nginx/conf.d/default.conf // 修改配置文件
然后使用 ctrl + p + q 退出容器，使用 exit 的话会让容器停止。
docker cp mynginx:/etc/nginx/conf.d/default.conf ./default.conf

https://learnku.com/articles/38766
```
### git 笔记
```javascript
git clone 命令默认的只会建立master分支 // 特别提醒
git clone -b [new_branch_name]  仓库地址 // clone时创建新的分支替代默认origin/master
git clone 仓库地址  // 从远程库拉到本地 文件名为仓库名 如 git@gitee.com:momingsixiali/git.git 拉到本地文件名为 git
git clone 仓库地址 "指定目录" // 拉到本地文件名 为 指定的目录 如 git clone git@gitee.com:momingsixiali/git.git zhiding 本地文件名为 zhiding

git mv demo demo1 // 不会破坏git历史 等效于 如下:
mv demo demo1 // 修改文件名
git add demo1 // 添加到暂存区
git rm demo // 更改demo的提交历史到 demo1

git reset --hard // 危险命令 分支的指针都指向上一个提交  无法找回 移动 HEAD->更新索引->更新暂存区工作区
git reset --soft  //  分支的指针都指向上一个提交 本次提交还在 只是不显示
git reset --mixed  //  分支的指针都指向上一个提交 只是回退暂存区 工作区还在 推荐使用 也是 git 默认

git grep login // 查找该仓库里所有使用'login'的地方 相当于 Linux中的 grep 返回如下
    app/Http/Controllers/Auth/LoginController.php:     * Where to redirect users after login.
git grep -n login // 显示 行号 
git grep --name-only login // 只显示文件名
   app/Http/Controllers/Auth/LoginController.php
   git grep -c login // 查看每个文件里有多少行匹配
      app/Http/Controllers/Auth/LoginController.php:1
 git grep login 5027c63 // 指定提交索引 找
 git grep -e 'name' --and -e email // 同时满足 name 和 email 
    app/Models/User.php:        'name', 'email', 'password',
    composer.lock:            "name": "egulias/email-validator",
 git grep --all-match -e 'name' -e email 97bacf05d4 // 满足name 或 email 
 git grep -e 'name' --and  -e  -e MAX .
 git grep -e 'password' --and ( -e name -e email ) //  同时满足 password 和 (name 或者 email)
 // 可组合使用
 git grep  -n -e 'password' --and -e email 97bacf05d4
 
 git log -p // 显示每个commit具体修改的内容，输出的形式以diff的形式给出
 git show // 同git log -p输出类似，不同在于show只显示一个commit的内容，如果不指定commit hash, 它默认输出HEAD指向commit的内容
 git shortlog // 显示汇总信息，以用户进行分类 返回如下
     moming (6):
           Merge branch 'dev' of https://github.com/wujianan/shop into dev
           添加忽略文件
           注册登录
           邮箱验证功能
     momingsixiali (1):
           项目初始化
   git shortlog -s // 显示用户 提交次数 按提交时间排序
   git shortlog -n // 显示用户 提交次数 进行倒序排列
 git log  --author=moming // 显示 moming 的提交, 限定输出给定的用户
 git log -2 // 限制 显示输出的数量 本次输出 2个
 git log --after '12-22-2019'  //  --after和--before 限定指定日期的log
 git log --decorate --oneline // 显示对应commit所属的branch和tag信息
 git log --all // 所有分支
 git log --graph // 演化历史 包括所有分支
 git log --oneline  // 简化输出  
   git show 72939  // 显示指定提交的相关信息
   git show 72939^{tree} //显示指定提交的目录结构
   git show v1  // 显示指定 tag 
git diff // 显示工作区 和暂存区的 不同
git diff --stat // 显示简单的 比较信息
git diff master // 查看当前分支 与 master 分支的 不同之处
git diff SHA1 SHA2 // 比较两个历史版本之间的差异   
   git push <远程主机名> <本地分支名>:<远程分支名> // 将本地分支的更新，推送到远程
   git push origin :master // 危险 删除远程仓库的分支 等效于 git push origin --delete master
   git push //当前分支只有一个追踪分支 可省略 <远程主机名> <本地分支名>:<远程分支名>
   git push -u origin master // 将本地的master分支推送到origin远程，同时指定origin为默认，后面就可以不加任何参数使用git push
   git fetch 和 git pull  // 功能是大致相同,都是起到了更新代码的作用 git pull看起来更像git fetch + get merge 建议使用 git fetch + get merge   git pull 一旦代码有问题，很难找到出错的地方https://learnku.com/articles/38780
```
### Shell-变量高级用法
```javascript
echo ${PATH/bin/BIN}    // 单个替换
echo ${PATH//bin/BIN}   // 全部替换
echo ${#var_str}
[wonbin@localhost ~]$ string="everything is just beginning"
[wonbin@localhost ~]$ echo `expr index "$string" ux`
16
echo ${var_str:3:5}  // 方法二， 开始位置3， 长度5
echo `expr substr "$var_str" 1 5`   // 方法五， 索引从开始1计数
https://learnku.com/articles/39190
```
### 删除文件占用空间
```javascript
在清理过服务器上一个高达 100 多 G 的文件后，使用 df -h 查看存储空间仍然 100%。使用 du -h -x --max-depth=1 进行查看与 df -h 的结果不一致
使用 lsof |grep deleted 进行查看是否有删除操作的异常进程

发现有一个 php 进程在占用， kill 掉相关进程后恢复正常https://learnku.com/articles/39534
```

[Linux 性能优化笔记](https://learnku.com/articles/39274)


[Nginx+rtmp 模块搭建流媒体视频点播服务](https://learnku.com/articles/37335)

[Docker — 从入门到实践](https://github.com/yeasy/docker_practice)

[linux wiki](https://learnku.com/linux/wikis/36492)

[Nginx 站点开启 HTTPS ](https://learnku.com/articles/37287)

[Docker 中安装 RabbitMQ](https://learnku.com/articles/37157#reply119179)

[Nginx 内嵌变量](https://learnku.com/articles/36986)

[Git 实现 Laravel 项目的自动化部署](https://learnku.com/articles/33689)

[Nginx 代理缓存](https://learnku.com/articles/36857)

[Git 的代码自动发布](https://learnku.com/articles/36852#reply118312)

[Elasticsearch  es安装和简单配置](https://learnku.com/articles/36207)

[配置安全的 SSH 服务](https://learnku.com/linux/t/36120)

[使用 fail2ban 来防范 SSH 暴力破解](https://learnku.com/linux/t/36233)

[在线crontab](https://crontab.guru/)

[docker 快速搭建稳定安全的开发/生产环境](https://github.com/jianyan74/dockerfiles)

[windows 10 WSL编码](https://gleehub.com/program/wsl-xia-you-ya-di-coding.html)

[初识 Shell](https://learnku.com/articles/33469)

[html 转 pdf 命令行工具 wkhtmltopdf ](http://einverne.github.io/post/2019/01/html-to-pdf.html)

[Centos7 搭建 Nextcloud个人网盘](https://me.jinchuang.org/archives/301.html)

[三十分钟学会sed](https://github.com/mylxsw/growing-up/blob/master/doc/%E4%B8%89%E5%8D%81%E5%88%86%E9%92%9F%E5%AD%A6%E4%BC%9ASED.md)

[Linux工具快速教程](https://linuxtools-rst.readthedocs.io/zh_CN/latest/index.html)

[看例子学sed](http://qinghua.github.io/sed/)

[工作中常用的 Linux 命令](https://michael728.github.io/2018/07/05/linux-useful-commands-in-work/)

[工作中常用的 Shell 命令及技巧](https://michael728.github.io/2019/04/14/linux-useful-shell-commands-in-work/)

[PHPer 必知必会的 Linux 命令](https://linux.hellocode.name/user-group.html)

[Linux工具快速教程](https://linuxtools-rst.readthedocs.io/zh_CN/latest/index.html#)

[你可能不知道的shell技巧](https://segmentfault.com/a/1190000016648034)

[wget的15个震撼的例子](https://neuqzxy.github.io/2017/07/08/wget%E7%9A%8415%E4%B8%AA%E9%9C%87%E6%92%BC%E7%9A%84%E4%BE%8B%E5%AD%90/)

[Linux 踩坑记](https://www.restran.net/2015/10/19/linux-practice-notes/)

[PHPer 必知必会的 Linux 命令](https://github.com/Nick233333/phper-linux-gitbook)

[命令行的艺术](https://github.com/jlevy/the-art-of-command-line)

[Nginx 学习笔记时序图](https://www.njphper.com/posts/680ebdf2.html)

[Windows 10 安装体验](https://learnku.com/articles/28500)

[打造高效的工作环境 – SHELL 篇https://github.com/coolshellx/articles](https://coolshell.cn/articles/19219.html)


[工作中常用的 Linux 命令](https://michael728.github.io/2018/07/05/linux-useful-commands-in-work/)