---
title: linux常用命令收集
date: 2018-12-27 10:14:14
tags:
- linux
---
### sed
```javascript
删除某行

对98k.txt的行进行操作，将操作结果输出到终端（只是做模拟操作，不改动源文件）

sed "1d" 98k.txt         # 输出删除第一行后的文件内容
sed "$d" 98k.txt         # 输出删除最后一行后的文件内容
sed "1,2d" 98k.txt       # 输出删除第一行到第二行后的文件内容
sed "2,$d" 98k.txt       # 输出删除第2行到最后1行后的文件内容

显示某行

sed -n "1p" 98k.txt           # 只显示文件的第一行 
sed -n "$p" 98k.txt           # 只显示文件的最后一行
sed -n "1,2p" 98k.txt         # 只显示文件的第一行到第二行
sed -n "2,$p" 98k.txt         # 显示文件的第二行到最后一行

使用安静模式进行查询

sed -n "/ruby/p" 98k.txt
输出关键字ruby所在行的内容；其中"/str/p"，str为搜索的文本内容
sed -n "/\$/p" 98k.txt
输出关键字$所在行的内容，使用反斜线\屏蔽特殊含义

增加一行或多行字符串

sed "1a drink tea" 98k.txt            # 在第一行后增加字符串"drink tea"
sed "1,3a drink tea" 98k.txt          # 在第一行到第三行后增加字符串"drink tea"
sed "1a drink tea\nor coffee" 98k.txt # 在第一行后增加两行，换行使用\n，可多次使用\n添加多行

增加另外一个文件的内容

sed "1r 1.txt" 98k.txt     # 把1.txt的内容增加到98k.txt的第一行后

替代一行或多行

sed "1c Hi" 98k.txt    # 把98k.txt的第一行替换为Hi
sed "1,2c Hi" 98k.txt  # 把98k.txt的第一行到第二行替换为Hi

替换一行中的某部分字符串

格式：sed "s/要替换的字符串/新的字符串/g" 98k.txt （要替换的字符串可以用正则表达式）

sed "s/ruby/bird/g" 98k.txt   # 把全部的ruby替换为bird
sed "s/ruby//g" 98k.txt       # 把全部的ruby替换为空，即删除ruby字符串

# 对每行匹配到的第一个字符串进行替换
sed -i "s/原字符串/新字符串/" 98k.txt

# 对全局匹配上的所有字符串进行替换
sed -i "s/原字符串/新字符串/g" 98k.txt

# 删除所有匹配到字符串的行
sed -i "/匹配字符串/d"  98k.txt

# 特定字符串的行后插入新行
sed -i "/特定字符串/a 新行字符串" 98k.txt

# 特定字符串的行前插入新行
sed -i "/特定字符串/i 新行字符串" 98k.txt

# 把匹配行中的某个字符串替换为目标字符串
sed -i "/匹配字符串/s/源字符串/目标字符串/g" 98k.txt

# 在文件98k.txt中的末行之后，添加bye
sed -i "$a bye" 98k.txt

# 对于文件第3行，把匹配上的所有字符串进行替换
sed -i "3s/原字符串/新字符串/g" 98k.txt

echo hello|sed 's/hello/(&)/' #将hello放在扩号中
sed -i '/DEVICE/c\Ethernet' test 
nl /etc/passwd | sed '2i drink tea' 
sed -i '/connect/s#YES#NO#' test    #匹配connect的行，把YES替换成NO 
 将文件的分隔符从逗号更改为管道
head mydata.csv | sed 's/,/|/g'
```
### sort
```javascript
sort [-fbMnrtuk] [file or stdin]
选项与参数：
-f  ：忽略大小写的差异，例如 A 与 a 视为编码相同；
-b  ：忽略最前面的空格符部分；
-M  ：以月份的名字来排序，例如 JAN, DEC 等等的排序方法；
-n  ：使用『纯数字』进行排序(默认是以文字型态来排序的)；
-r  ：反向排序；
-u  ：就是 uniq ，相同的数据中，仅出现一行代表；
-t  ：分隔符，默认是用 [tab] 键来分隔；
-k  ：以那个区间 (field) 来进行排序的意思

 
sort -m file1 file2 合并两个文件
sort file1>file1；cat file1，你会得到一个空文件。这时候要使用-o参数来实现这个功能。
-n是按照数字大小排序，-r是以相反顺序，-k是指定需要爱排序的栏位，-t指定栏位分隔符为冒号
sort file1 -o file1
sort -u是全文本去重，而uniq是比较相邻行，将第二个及以后更多重复行删去。
sort file2 |uniq -c file
删除重复行：

　　uniq file.txt 　　

　　sort file.txt | uniq 　　

　　sort -u file.txt

　　只显示单一行：

　　uniq -u file.txt 　　

　　sort file.txt | uniq -u

　　统计各行在文件中出现的次数：

　　sort file.txt | uniq -c

　　在文件中找出重复的行：

　　sort file.txt | uniq -d

 
　　利用sort和uniq求两个文件的并集，交集和差集

　　并集：cat file1.txt file2.txt | sort | uniq > file.txt

　　交集：cat file1.txt file2.txt | sort | uniq -d >file.txt

　　差集：求file1.txt相对于file2.txt的差集，可先求出两者的交集temp.txt，然后在file1.txt中除去temp.txt即可。

　　　　　cat file1.txt file2.txt | sort | uniq -d >temp.txt

　　　　　cat file1.txt temp.txt | sort | uniq -u >file.txt
sort -u 会达到和典型的 sort file.txt | uniq 模式一样的结果
sort -t"," -k2,2 filename.csv
egrep "php.*artisan" 匹配php artisan
grep "first_value\|second_value" filename.csv
```
### cut
```javascript
删除第一和第三列cut -d, -f 1,3 filename.csv
```
### 合并文件
```javascript
# names.txt
adam
john
zach
# jobs.txt
lawyer
youtuber
developer
# Join the two into a CSV
paste -d ',' names.txt jobs.txt > person_data.txt
# Output
adam,lawyer
john,youtuber
zach,developer
```
### awk
```javascript
awk -F":" '{print $1}'  /etc/passwd
 awk -F":" '{print $1,$3}'  /etc/passwd                          #多了一个逗号，$1与$3使用空格分隔
 awk -F":" '{print "Username:" $1 "\t\t Uid:" $3 }' /etc/passwd  #自定义输出  
 awk -F: '{print NF}' /etc/passwd                                #显示每行有多少字段
 awk -F: '{print $NF}' /etc/passwd                               #将每行第NF个字段的值打印出来
 awk -F: 'NF==4 {print}' /etc/passwd                             #显示只有4个字段的行
 awk -F: 'NF>2{print $0}' /etc/passwd                            #显示每行字段数量大于2的行
 awk -F: '{print NR,NF,$NF,"\t",$0}' /etc/passwd                 #依次打印行号，字段数，最后字段值，制表符，每行内容
 awk -F: 'NR==5 || NR==6{print}'  /etc/passwd                    #显示第5行和第6行
 //匹配代码块
 //纯字符匹配   !//纯字符不匹配   ~//字段值匹配    !~//字段值不匹配   ~/a1|a2/字段值匹配a1或a2   
 awk '/mysql/{print $0}' /etc/passwd              #三条指令结果一样
 awk '!/mysql/{print $0}' /etc/passwd             #输出不匹配mysql的行
 awk '!/mysql|mail/{print}' /etc/passwd           #输出不匹配mysql或mail的行
 awk '/[2][7][7]*/{print $0}' /etc/passwd         #匹配包含27为数字开头的行，如27，277，2777...
 awk -F: '$1~/mail/{print $1}' /etc/passwd        #$1匹配指定内容才显示
 awk -F: '$1!~/mail|mysql/{print $1}' /etc/passwd        

 IF语句 必须用在{}中，且比较内容用()扩起来
 awk -F: '{if($1~/mail/) print $1}' /etc/passwd                                     
 awk -F: '{if($1~/mail/) {print $1}}'  /etc/passwd                              
 awk -F: '{if($1~/mail/) {print $1} else {print $2}}' /etc/passwd  #if...else...

 条件表达式 ==   !=   >   >=  
 awk -F":" '{if($1=="mysql") print $3}' /etc/passwd          //与上面相同 
 awk -F":" '$1!="mysql"{print $3}' /etc/passwd               //不等于
 awk -F":" '$3>1000{print $3}' /etc/passwd                   //大于

 逻辑运算符 &&　|| 
 awk -F: '{if($1~/mail/ && $3>8) print }' /etc/passwd
 awk -F: '{if($1~/mail/ || $3>1000) print }' /etc/passwd 
 删除重复行
 
 $ awk '!($0 in array) { array[$0]; print}' temp
 打印/etc/passwd中所有包含同样的uid和gid的行
 
 $ awk -F ':' '$3=$4' /etc/passwd
 打印文件中的指定部分的字段
 
 $ awk '{print $2,$5;}' employee.txt
 比较的时候忽略空白符
 
 $ diff -w name_list.txt name_list_new.txt
 下载文件中列出的所有url对应的页面
 
 $ cat url-list.txt | xargs wget –c
 #替代grep
 awk '/word/' filename.csv
 对于所有带我们指定单词 word 的行，awk 打印第三和第四列，用 tab 分隔。-F, 用于指定切分时的列分隔符为逗号。
 awk -F, '/word/ { print $3 "\t" $4 }' filename.csv
 要获取文件中的第 53 条记录
 awk -F, 'NR == 53' filename.csv
 打印第一列等于给定字符串的行的行号和列
 awk -F, ' $1 == "string" { print NR, $0 } ' filename.csv
 awk -F, ' $3 >= 2005 && $5 <= 1000 { print NR, $0 } ' filename.csv
 求出第三列的总和
 awk -F, '{ x+=$3 } END { print x }' filename.csv
 组合多个 CSV 文件，忽略标题，然后在最后附加它
 awk 'FNR==1 && NR!=1{next;}{print}' *.csv > final_file.csv
 内置函数 gsub() 替换多个值
 awk '{gsub(/scarlet|ruby|puce/, "red"); print}'
 打印出现了两次的行
 awk -F, '++seen[$0] == 2' filename.csv
 获取文件的行列数：
 awk -F, 'END { print NF, NR }' filename.csv
 # Prettier version
 awk -F, 'BEGIN { print "COLUMNS", "ROWS" }; END { print NF, NR }' filename.csv
根据第一列去重，相同的保留第二列值最大的那个https://segmentfault.com/q/1010000000665713
fdf     284 
asd     112
adf     146
csb     513
dfg     576
asd     346
adf     263
csb     092
dfg     547
[root@VM_0_14_centos ~]# cat awk.txt | sort -rnk2 | awk '{if (!keys[$1]) print $0; keys[$1] = 1;}'
dfg     576
csb     513
asd     346
fdf     284
adf     263
先按第二列数字大小逆序，然后再按第一列去重，这样就能得到第二列最大的非重复行数据。
[root@VM_0_14_centos ~]# sort -rnk2,2 awk.txt |sort -uk1,1

adf     263
asd     346
csb     513
dfg     576
fdf     284
第一列等于 something 的那些行，求出第三列值的总和
awk -F, '$1 == "something" { x+=$3 } END { print x }' filename.csv
```
### 快捷键
```javascript
$ bind -p
"\C-g": abort
"\C-x\C-g": abort
"\e\C-g": abort
"\C-j": accept-line
查找所有使用了Control键的绑定https://gywbd.github.io/posts/2014/11/linux-keybindings.html
$ bind -p | grep '\\c'
```
### 解压
```javascript
创建一个新的tar文件

$ tar cvf archive_name.tar dirname/
解压tar文件

$ tar xvf archive_name.tar
查看tar文件

$ tar tvf archive_name.tar
```
### 测试并发
```javascript
ab -n 100 -c 10 -l http://www.your_site.com
-n number 总的请求数
-c concurrency 并发数 
-l 表示当某个请求的回复长度不与第一个请求的回复长度一致时，不把它作为失败的请求
POST方法：https://shuwoom.com/?p=1542

ab -n 100 -c 10 -p post.txt http://xxx/test.php
post.txt里面是参数，如data={"name":"wgc"}，但是要url编码以后的参数
```
### 查看当前目录下各个文件或文件夹的大小
```javascript
[root@VM_0_14_centos ~]# du -h --max-depth=1 .
7.5M    ./.config
5.8M    ./imgbed-project
1.7M    ./Chatroom
8.0K    ./.httpie
20K     ./.ssh
2.7M    ./lnmp-docker
101M    ./daily-signer
708K    ./pick-1.9.0
32M     ./gaga
688K    ./.acme.sh
1.9M    ./dockser-server
3.4M    ./shadowsocksr
```
### 查找字符串
```javascript
find ./*|xargs grep debug
#https://github.com/BurntSushi/ripgrep/
[root@VM_0_14_centos ~]# rg 'redis'
imgbed-project/LICENSE
627:free software which everyone can redistribute and change under these terms.
637:    This program is free software: you can redistribute it and/or modify
657:    This is free software, and you are welcome to redistribute it
```
### Nginx 日志统计 ip 访问数
```javascript
切割日志

查找7月17日访问log导出到17.log文件中：

cat gelin_web_access.log | egrep "17/Jul/2017" | sed  -n '/00:00:00/,/23:59:59/p' > /tmp/17.log
查看访问量前10的IP

awk '{print $1}' 17.log | sort | uniq -c | sort -nr | head -n 10 
查看访问前10的URL

awk '{print $11}' gelin_web_access.log | sort | uniq -c | sort -nr | head -n 10
查询访问最频繁的URL

awk '{print $7}' gelin_web_access.log | sort | uniq -c | sort -n -k 1 -r | more
查询访问最频繁的IP

awk '{print $1}' gelin_web_access.log | sort | uniq -c | sort -n -k 1 -r | more
根据访问IP统计UV

awk '{print $1}' gelin_web_access.log | sort | uniq -c | wc -l
统计访问URL统计PV

awk '{print $7}' gelin_web_access.log | wc -l
根据时间段统计查看日志

cat gelin_web_access.log | sed -n '/17\/Jul\/2017:12/,/17\/Jul\/2017:13/p' | more
[root@VM_0_14_centos ~]# cat /var/log/nginx/access.log|more
120.132.3.65 - - [21/Dec/2018:06:28:57 +0800] "GET http://www.qq.com/404/search_children.js HTTP/1.1" 404 3650 "-" "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/35.0.1916.114 Safari/537.36" "-"
120.132.3.65 - - [21/Dec/2018:06:28:57 +0800] "\x04\x01\x00PpTi4\x00" 400 173 "-" "-" "-"
120.132.3.65 - - [21/Dec/2018:06:28:57 +0800] "\x05\x01\x00" 400 173 "-" "-" "-"
58.150.60.162 - manager [21/Dec/2018:08:08:21 +0800] "POST /WEB_VMS/LEVEL15/ HTTP/1.1" 404 3650 "-" "-" "-"
95.213.177.123 - - [21/Dec/2018:08:36:15 +0800] "CONNECT check.proxyradar.com:80 HTTP/1.1" 400 173 "-" "-" "-"
60.191.52.254 - - [21/Dec/2018:09:35:18 +0800] "HEAD http://112.124.42.80:63435/ HTTP/1.1" 200 0 "-" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/53.0.2785.143 Safari/537.36" "-"
80.82.70.187 - - [21/Dec/2018:09:47:37 +0800] "GET http://www.baidu.com/cache/global/img/gs.gif HTTP/1.1" 404 3650 "-" "Mozilla" "-"
139.162.81.62 - - [21/Dec/2018:10:33:03 +0800] "GET http://clientapi.ipip.net/echo.php?info=1234567890 HTTP/1.1" 404 3650 "-" "Go-http-client/1.1" "-"
[root@VM_0_14_centos ~]# cat /var/log/nginx/access.log|awk '{print $1}'|sort|uniq -c|sort -nrk1
      3 120.132.3.65
      1 95.213.177.123
      1 80.82.78.50
      1 80.82.70.187
      1 60.191.52.254
      1 58.150.60.162
      1 139.162.81.62
at /var/log/nginx/access.log|awk '{ipArr[$1]++} END{for( item in ipArr) print item,ipArr[item]}' | sort -r -k
2
1.根据访问IP统计UV
awk '{print $1}' access.log|sort | uniq -c |wc -l

2.统计访问URL统计PV
awk '{print $7}' access.log|wc -l

3.查询访问最频繁的URL
awk '{print $7}' access.log|sort | uniq -c |sort -n -k 1 -r|more

4.查询访问最频繁的IP
awk '{print $1}' access.log|sort | uniq -c |sort -n -k 1 -r|more

5.根据时间段统计查看日志
cat access.log| sed -n '/14\/Mar\/2015:21/,/14\/Mar\/2015:22/p'|more
```
### 文件比较（交集、差集）
```javascript
交集（打印两个文件相同的行）
[root@VM_0_14_centos ~]# cat aaa.txt
aaa
bbb
ccc
ddd
eee
111
222
[root@VM_0_14_centos ~]# cat bbb.txt
bbb
ccc
aaa
hhh
ttt
jjj
[root@VM_0_14_centos ~]# comm -12 <(sort aaa.txt) <(sort bbb.txt)
aaa
bbb
ccc
求差（打印两个文件中不相同的行）
[root@VM_0_14_centos ~]# comm -3 <(sort aaa.txt) <(sort bbb.txt)
111
222
ddd
eee
        hhh
        jjj
        ttt
[root@VM_0_14_centos ~]# comm -3 <(sort aaa.txt) <(sort bbb.txt)|sed 's/^\t//' 
111                                                                            
222                                                                            
ddd                                                                            
eee                                                                            
hhh                                                                            
jjj                                                                            
ttt     
aaa.txt的差集
[root@VM_0_14_centos ~]# comm -23 <(sort aaa.txt) <(sort bbb.txt)
111
222
ddd
eee
bbb.txt的差集
[root@VM_0_14_centos ~]# comm -13 <(sort aaa.txt) <(sort bbb.txt)
hhh
jjj
ttt
```
### 转换编码
```javascript
iconv -f ISO-8859-1 -t UTF-8 < input.txt > output.txt
```
### 执行算术运算
```javascript
expr 5 + 2
echo $[16 + 4]#https://www.itcodemonkey.com/article/11866.html
```
### send email
```javascript
[root@VM_0_14_centos ~]# wget http://caspian.dotconf.net/menu/Software/SendEmail/sendEmail-v1.56.tar.gz
--2018-12-20 16:40:34--  http://caspian.dotconf.net/menu/Software/SendEmail/sendEmail-v1.56.tar.gz
Resolving caspian.dotconf.net (caspian.dotconf.net)... 159.89.153.157
Connecting to caspian.dotconf.net (caspian.dotconf.net)|159.89.153.157|:80... connected.
HTTP request sent, awaiting response... 200 OK
Length: 29740 (29K) [application/octet-stream]
Saving to: ‘sendEmail-v1.56.tar.gz’

100%[===============================================================================================>] 29,740       159KB/s   in 0.2s

2018-12-20 16:40:35 (159 KB/s) - ‘sendEmail-v1.56.tar.gz’ saved [29740/29740]

[root@VM_0_14_centos ~]# tar -zxvf sendEmail-v1.56.tar.gz
sendEmail-v1.56/
sendEmail-v1.56/CHANGELOG
sendEmail-v1.56/README
sendEmail-v1.56/README-BR.txt
sendEmail-v1.56/TODO
sendEmail-v1.56/sendEmail
sendEmail-v1.56/sendEmail.pl
[root@VM_0_14_centos ~]# cd sendEmail-v1.56/
[root@VM_0_14_centos sendEmail-v1.56]# mv sendEmail /usr/local/bin
#  /usr/local/bin/sendEmail -f ttlsafrom@163.com -t ttlsato@qq.com \
    -s smtp.163.com -u "我是邮件主题" -o message-content-type=html \
    -o message-charset=utf8 -xu ttlsafrom@163.com -xp 123456 -m "我是邮件内容"
    /usr/local/bin/sendEmail 命令主程序
    -f ttlsafrom@163.com  发件人邮箱
    -s smtp.163.com       发件人邮箱的smtp服务器
    -u "我是邮件主题"     邮件的标题
    -o message-content-type=html   邮件内容的格式,html表示它是html格式
    -o message-charset=utf8        邮件内容编码
    -xu ttlsafrom@163.com          发件人邮箱的用户名
    -xp 123456               发件人邮箱密码
    -m "我是邮件内容"        邮件的具体内容
```
### wc
```javascript
1.统计当前目录下，py文件数量：

find . -name "*.py" |wc -l
2.统计当前目录下，所有py文件行数：

find . -name "*.py" |xargs cat|wc -l
3.统计当前目录下，所有py文件行数，并过滤空行：

find . -name "*.py" |xargs cat|grep -v ^$|wc -l
```
### kill
```javascript
kill ps -ef | grep 'ddd'
for procid in $(ps -aux | grep "some search" | awk '{print $2}'); do kill -9 $procid; done
ps -ef | grep 'ddd' | xargs kill
 echo '--help' | xargs cat 等价于 cat --help
 echo '11@22@33' | xargs -d '@' echo//11 22 33
 echo '11@22@33' | xargs -p -d '@' echo//不会马上执行其后面的命令，而是输出即将要执行的完整的命令 echo 11 22 33
 ?...y ==>这里询问是否执行命令 echo 11 22 33 输入y并回车，则显示执行结果，否则不执行
 https://laravel-china.org/articles/21339
 find . -name "*.txt"
 输出：
 
 ./2.txt
 ./3.txt
 ./1.txt     => 默认情况下find的输出结果是每条记录后面加上换行，也就是每条记录是一个新行
 
 find . -name "*.txt" -print0
 输出：
 
 ./2.txt./3.txt./1.txt     => 加上 -print0 参数表示find输出的每条结果后面加上 '\0' 而不是换行
 
 find . -name "*.txt" -print0 | xargs -0 echo
 输出：
 
 ./2.txt ./3.txt ./1.txt
 
 find . -name "*.txt" -print0 | xargs -d '\0' echo
 输出：
 ./2.txt ./3.txt ./1.txt
```
### uniq
```javascript
#uniq -h
长选项必须使用的参数对于短选项时也是必需使用的。  
 -c, --count              //在每行前加上表示相应行目出现次数的前缀编号  
 -d, --repeated          //只输出重复的行  
 -D, --all-repeated      //只输出重复的行，不过有几行输出几行  
 -f, --skip-fields=N     //-f 忽略的段数，-f 1 忽略第一段  
 -i, --ignore-case       //不区分大小写  
 -s, --skip-chars=N      //根-f有点像，不过-s是忽略，后面多少个字符 -s 5就忽略后面5个字符  
 -u, --unique            //去除重复的后，全部显示出来，根mysql的distinct功能上有点像  
 -z, --zero-terminated   end lines with 0 byte, not newline  
 -w, --check-chars=N      //对每行第N 个字符以后的内容不作对照  
 --help              //显示此帮助信息并退出  
 --version              //显示版本信息并退出 
显示有重复的行
$ uniq -d -c uniqtest  
  3 this is a test  
  2 i love tank 
  uniq -D 只显示重复的行，并且把重复几行都显示出来。他不能和-c一起使用
  仅显示不重复的行 sort testfile | uniq -u
```
### curl 
```javascript
查询访问时间
for i in {1..100};do curl -o /dev/null -s   -w "$i | time_namelookup: %{time_namelookup} | time_connect: %{time_connect} | time_starttransfer: %{time_starttransfer} | time_total: %{time_total}\n" -x "10.71.48.129:80" "http://www.baidu.com"; done

```
### ftp
```javascript
yum install vsftpd
启动ftp命令#service vsftpd start

停止ftp命令#service vsftpd stop

重启ftp命令#service vsftpd restart
[root@VM_0_14_centos ~]# useradd test
[root@VM_0_14_centos ~]# passwd test
Changing password for user test.
New password:
BAD PASSWORD: The password is shorter than 8 characters
Retype new password:
Sorry, passwords do not match.
New password:
Retype new password:
passwd: all authentication tokens updated successfully.
[root@VM_0_14_centos ~]# ll /home/test/
total 0
[root@VM_0_14_centos ~]# cd /home/test/
[root@VM_0_14_centos test]# touch test.php
然后使用filezilla链接ftp test账号登录看到的就是/home/test/下的文件
```
### git
```javascript
使用通配符提交 git add *.js
只删除版本库中文件但保存项目目录中文件 git rm --cached index.php
放弃没有提交的修改 git checkout .
删除没有add 的文件和目录 git clean -fd
显示将要删除的文件或目录 git clean -n
查看最近2次提交日志并显示文件差异 git log -p -2
一行显示并只显示SHA-1的前几个字符 git log --oneline
git config --global alias.c commit 使用 git c 实现 git commit  一样的效果了
$ git log --graph --pretty=format:'%Cred%h%Creset -%C(yellow)%d%Creset %s %Cgreen(%cr) %C(bold blue)<%an>%Creset' --abbrev-commit
*   1edc0f8c - (HEAD -> temp, origin/master, origin/HEAD, master) Merge branch 'master' into temp (3 hours ago) <xxx>
|\
| * 7bd6895a - Merge branch 'dev'pay/right优化 (5 hours ago) <xxx>
| *   d81f7be5 - Merge branch 'temp' (6 hours ago) <xxx>
创建并切换分支 git checkout -b feature/bbs
删除远程分支 git push origin :dev
储藏工作 git stash
查看储藏列表 git stash list
应用最近的储藏 git stash apply
应用并删除储藏 git stash pop
对mster分支代码生成压缩包供使用者下载使用，--prefix 指定目录名
git archive master --prefix='hdcms/' --format=zip > hdcms.zip

删除远程ask分支 git push origin --delete ask
本地ask分支关联远程分支并推送 git push --set-upstream origin ask
# 增加一个远程库
git remote add github git@github.com:houdunwang/coding.git

# 提交到远程库
git push github
git remote add origin git@github.com:houdunwang/hd-xj.git
拉取origin主机的ask分支与本地的master分支合并 git pull origin ask:ask
拉取origin主机的ask分支与当前分支合并 git pull origin ask
```
### 查找清理大文件
```javascript
[cuihuan:~ cuixiaohuan]$ df -h
Filesystem Size Used Avail Use% Mounted on
/dev/sda2 8.2G 6.7G 1.6G 82% /
/dev/sda3 1.4T 1.3T 50G 97% /home
1.5T的硬盘占用了97%，确实不够用了
[cuihuan:~]$ du -sh * | grep G
。。。
73G mongodb
103G mxm
2.1G online

http://cuihuan.net/2015/12/08/linux%20%E6%9F%A5%E6%89%BE%E6%B8%85%E7%90%86%E5%A4%A7%E6%96%87%E4%BB%B6/

```
### crontab 误删除恢复
```javascript
cat /var/log/cron | grep -i "`which cron`" > ./all_temp
cat  ./all_temp | grep -v "<command>” > ./cmd_temp
awk -F'(' '/crond/{a[$3]=$0}END{for(i in a)print a[i]}' /var/log/cron* >crontab.txt

从crontab.txt 中找出每一条指令，然后在cmd_temp 中匹配运行次数，重新编辑crontab 添加
每天对crontab进行备份，备份最近15天的数据。
#!/bin/bash
# 每天对crontab 进行备份 ，同时删除最近15天的数据
DATE=$(date +%Y%m%d)
crontab -l > /home/work/bak/crontab_$DATE.bak
find /home/work/bak/ -mtime +15 -name '*.bak' -exec rm -rf {} \;
http://cuihuan.net/2015/12/03/crontab%20%E8%AF%AF%E5%88%A0%E9%99%A4%E6%81%A2%E5%A4%8D/
```
[linux 常用命令top、awk、sed等](https://segmentfault.com/a/1190000016837948)

[sed很强大的文本操作命令](http://blog.51yip.com/shell/986.html)

[ubuntu sentry 安装配置](http://blog.51yip.com/server/1960.html)

[数据科学家的命令行技巧](https://linux.cn/article-10342-shareweibo.html)

[xargs 命令详解](https://laravel-china.org/articles/21339)

[Linux 命令行的艺术](https://github.com/jlevy/the-art-of-command-line/blob/master/README-zh.md)

[linux下去除重复行命令uniq](http://blog.51yip.com/shell/1022.html)

[50个最常用的Unix/Linux命令 ](https://gywbd.github.io/posts/2014/8/50-linux-commands.html)

[看示例学awk](https://mp.weixin.qq.com/s/6YVC9hA2fMEjclWmseevXA)

[Sed 命令完全指南 ](https://linux.cn/article-10232-1.html)

[awk查看统计Nginx访问日志](https://www.centos.bz/2017/07/nginx-awk-access-log/)

[Sed:一些常用的命令详解](https://www.centos.bz/2018/11/sed%E4%B8%80%E4%BA%9B%E5%B8%B8%E7%94%A8%E7%9A%84%E5%91%BD%E4%BB%A4%E8%AF%A6%E8%A7%A3/)

[提高工作效率的 VIM 操作](https://laravel-china.org/articles/21602)

[Git 基本使用文档](https://laravel-china.org/articles/21832)

[网络问题连不上网](https://learnku.com/articles/28904)